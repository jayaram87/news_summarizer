{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GzrTW_hbsKGY"
      },
      "outputs": [],
      "source": [
        "root = '/content/drive/MyDrive/news_summary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "NYCBlBqAsbQH",
        "outputId": "3eb6770e-7aef-462c-f3db-45569d57c77b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/news_summary'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(root)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Nsjy4DXrsgTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b434b437-4907-41f6-fad3-7d53da942957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3 MB 33.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 23.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 61.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 70.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rQob1xMYs2xD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "5273c6e912174685bd478ae95a4cd647",
            "627d0100f5034ad2a9899cd6fd6e534e",
            "fa72dcb77df74acfba650f1383261e6b",
            "b6c04d150a69466e9fb35674cc6f8a8a",
            "b9fe96f43d874459a54183919589509c",
            "4c2548d3c5414f919488fbb494da5005",
            "0af5fadefe3b40d8a0d2c1ad46296d5e",
            "76def81e75da4d6482bf5bd2c9b14f46",
            "a1611415a1fc43ffa15ab733e4baadaa",
            "9843882cfb1e47c89129a349b176fb81",
            "b2f5aa7c4af44fb39c2147fc929b4d66"
          ]
        },
        "outputId": "8dd4f2d3-c93b-4c4b-d097-d652385419bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5273c6e912174685bd478ae95a4cd647"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# t5forconditionalgeneration is a langauge model on top of the t5 generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsGhS7MotsvP",
        "outputId": "5114af8c-4547-43bf-beab-4d1c31c528f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 20 01:56:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "My2CHsAgsoxC",
        "outputId": "67140ae1-aada-48ea-d2b0-eb5788622fdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zVcbp5Cjux6t"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  TRAIN_BATCH_SIZE = 128\n",
        "  VAL_BATCH_SIZE = 2\n",
        "  TRAIN_EPOCHS = 2\n",
        "  VAL_EPOCHS = 1\n",
        "  LEARNING_RATE = 0.001\n",
        "  SEED = 42\n",
        "  MAX_LEN = 512 # article text max len\n",
        "  SUMMARY_LEN = 150 # summary text max len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V1KEq6-IuClG"
      },
      "outputs": [],
      "source": [
        "def df_processing(file_path, train_size=0.8, seed=Config.SEED):\n",
        "  df = pd.read_csv(file_path, encoding='latin1')\n",
        "  df = df[['text', 'ctext']] # text is the summary, ctext is the detailed news article\n",
        "  df['ctext'] = 'summarize: ' + df['ctext'] # required for T5model\n",
        "\n",
        "  train_df = df.sample(frac=train_size, random_state=seed)\n",
        "  val_df = df.drop(train_df.index).reset_index(drop=True)\n",
        "  train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "  return train_df, val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bGyNqUUPv0gg"
      },
      "outputs": [],
      "source": [
        "a, b = df_processing('/content/drive/MyDrive/news_summary/news_summary.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yZAVjFLTv_Ct",
        "outputId": "d30068fe-7aaf-432a-d232-cc697da30c58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  All restaurants, including five-star hotels, i...   \n",
              "1  The Chinese government has banned singer Justi...   \n",
              "2  Pakistan on Saturday accused India of targetin...   \n",
              "3  A 40-year-old woman in Hyderabad was burnt ali...   \n",
              "4  The Delhi Police has arrested a man working as...   \n",
              "\n",
              "                                               ctext  \n",
              "0  summarize: Come April and you won?t have to go...  \n",
              "1  summarize: ?I just need one more shot, second ...  \n",
              "2  summarize: Pakistan?s top military officer on ...  \n",
              "3  summarize: In a tragic incident, a woman was b...  \n",
              "4  summarize: A man who allegedly threatened to b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c395819-3975-4fc1-b638-a75d686ee69d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>All restaurants, including five-star hotels, i...</td>\n",
              "      <td>summarize: Come April and you won?t have to go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Chinese government has banned singer Justi...</td>\n",
              "      <td>summarize: ?I just need one more shot, second ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pakistan on Saturday accused India of targetin...</td>\n",
              "      <td>summarize: Pakistan?s top military officer on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A 40-year-old woman in Hyderabad was burnt ali...</td>\n",
              "      <td>summarize: In a tragic incident, a woman was b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Delhi Police has arrested a man working as...</td>\n",
              "      <td>summarize: A man who allegedly threatened to b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c395819-3975-4fc1-b638-a75d686ee69d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c395819-3975-4fc1-b638-a75d686ee69d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c395819-3975-4fc1-b638-a75d686ee69d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "a.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rfBdU9_wwB90",
        "outputId": "b7fa909c-5e0b-4520-a345-95db4af90fff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Hotels in Maharashtra will train their staff t...   \n",
              "1  The Congress party has opened a bank called 'S...   \n",
              "2  Tanveer Hussain, a 24-year-old Indian athlete ...   \n",
              "3  The remains of a German hiker, who disappeared...   \n",
              "4  A UK-based doctor, Manish Shah, has been charg...   \n",
              "\n",
              "                                               ctext  \n",
              "0  summarize: Hotels in Mumbai and other Indian c...  \n",
              "1  summarize: It sounds like satire, but make no ...  \n",
              "2  summarize: A 24-year-old Indian athlete has be...  \n",
              "3  summarize: The remains of a German hiker who d...  \n",
              "4  summarize: A GP who practised in east London h...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ccd59a0-f1fc-4da6-aa28-1c531e07847e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>summarize: Hotels in Mumbai and other Indian c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Congress party has opened a bank called 'S...</td>\n",
              "      <td>summarize: It sounds like satire, but make no ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tanveer Hussain, a 24-year-old Indian athlete ...</td>\n",
              "      <td>summarize: A 24-year-old Indian athlete has be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The remains of a German hiker, who disappeared...</td>\n",
              "      <td>summarize: The remains of a German hiker who d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A UK-based doctor, Manish Shah, has been charg...</td>\n",
              "      <td>summarize: A GP who practised in east London h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ccd59a0-f1fc-4da6-aa28-1c531e07847e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ccd59a0-f1fc-4da6-aa28-1c531e07847e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ccd59a0-f1fc-4da6-aa28-1c531e07847e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "b.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "ad3d067e8e2a477aa09113a6a01ed081",
            "9e1a19b3f5f44c15ae8e2a148439585a",
            "15560e5e66034b1f94fb5123e3bfb684",
            "debe180065ab41e384bb6a0c9a253e34",
            "a96d91b349674ebea858911f272bc9c5",
            "4a893bb481ae44e4bdcda75637192800",
            "dfd81a8693ae406688cec0b189598a60",
            "88b2d940855f47bd91fe8e81b49a0fbc",
            "e227c505776943eeb13b59777e676f52",
            "0a588340a73544738bcaa5d17b198759",
            "628f527741094e909ac5a5c53dfac24d",
            "9637848b238a45c1a1cdb63a79f18ee5",
            "ba1231681a33461e87edf3666d4d7fc5",
            "04826699bf514c3ab73810e52b866b52",
            "f8b3e624953740759b5f9724b388cbc3",
            "f329aad072d2404cbf732e1953485b7a",
            "0582e8d103ce430aaae6231fc9095f43",
            "851bc9a82d424c498c56d5f6d83d4d8d",
            "c527eaeca5714da395a5a9633fa096fc",
            "1df3cf28559f45f28ecd0566e17d4dba",
            "e4e8df09d0e5457489d404c4d28d9f9e",
            "a069e50e54eb488894718fbf757f8dbc"
          ]
        },
        "id": "97JRa9xdxpvy",
        "outputId": "80f68dde-a383-4ecf-c58c-06485db6f2ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad3d067e8e2a477aa09113a6a01ed081"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9637848b238a45c1a1cdb63a79f18ee5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[21820, 296, 3, 9, 9, 9, 9, 1, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tk = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "tk.batch_encode_plus(['hello world aaaa'], max_length=10, pad_to_max_length=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "Jx_CDIrBzLCU",
        "outputId": "7ac542d5-1623-4401-d050-d6d1244e64b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello world aaaa</s> <pad> <pad>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tk.decode([21820, 296, 3, 9, 9, 9, 9, 1, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TrsoydkIwKog"
      },
      "outputs": [],
      "source": [
        "class CustomNewsDataset(Dataset):\n",
        "  def __init__(self, df, tokenizer, article_len, summary_len):\n",
        "    self.df = df\n",
        "    self.text = self.df.text\n",
        "    self.ctext = self.df.ctext\n",
        "    self.sum_len = summary_len\n",
        "    self.src_len = article_len\n",
        "    self.tokenizer = tokenizer # T5TOkenizer\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    ctext = str(self.ctext[index])\n",
        "    ctext = ' '.join(ctext.split())\n",
        "\n",
        "    text = str(self.text[index])\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    src_tokens = self.tokenizer.batch_encode_plus([ctext], max_length=self.src_len, pad_to_max_length=True, return_tensors='pt')\n",
        "    target_tokens = self.tokenizer.batch_encode_plus([text], max_length=self.sum_len, pad_to_max_length=True, return_tensors='pt')\n",
        "\n",
        "    src_ids = src_tokens['input_ids'].squeeze().to(dtype=torch.long) # reducing to a 1d vector\n",
        "    src_mask = src_tokens['attention_mask'].squeeze().to(dtype=torch.long)\n",
        "    target_ids = target_tokens['input_ids'].squeeze().to(dtype=torch.long)\n",
        "    target_mask = target_tokens['attention_mask'].squeeze().to(dtype=torch.long)\n",
        "\n",
        "    return {\n",
        "        'source_ids': src_ids,\n",
        "        'source_mask': src_mask,\n",
        "        'target_ids': target_ids\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4vQ73ad104w",
        "outputId": "ebe47241-ba73-428d-ab68-bc7575cab0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:174: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zvponAh31miE"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomNewsDataset(a, tokenizer, Config.MAX_LEN, Config.SUMMARY_LEN)\n",
        "val_dataset = CustomNewsDataset(b, tokenizer, Config.MAX_LEN, Config.SUMMARY_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9bd5ajpU2bsv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = Config.TRAIN_BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    num_workers= 0\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = Config.VAL_BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    num_workers= 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNk2SIRc2t_x",
        "outputId": "32b64e91-fada-493c-c21d-57ad09dce701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source_ids': tensor([[21603,    10,    71,  ...,     0,     0,     0],\n",
              "         [21603,    10,  2106,  ...,     0,     0,     0]]),\n",
              " 'source_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'target_ids': tensor([[   71,  2131,  3441,    63,   144,    16,  6697,    31,     7, 27864,\n",
              "           7985,    65,  1380,     3,     9,   388,    12,     3,  5846,    15,\n",
              "              3,     9,   898,    18,  1201,    18,  1490,  3202,    16,   851,\n",
              "             13,   160,   384,    38, 19372,   227,   160,  4284,    47, 11970,\n",
              "             13,     3,  5846,    53,     8,   388,    31,     7,  4806,     6,\n",
              "           2095,   243,    30,  2875,     5,    37,   337,  1810,   225,    36,\n",
              "          12171,    28,     8, 11970,    31,     7,  4806,    38,  4831,     6,\n",
              "              8,  3309,  6098,  7760,     5,  5076, 10195,     8,   819,    13,\n",
              "              8,  2131,  3441,    63,   144,     5,     1,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [16675,    53,  5923,  3271, 13346, 12524,  5073,    23,    30,     8,\n",
              "           5333,    13,  4425, 14128,  3690,     6,  2106,  3272,     3, 16911,\n",
              "           5116,  3271,  2255,  1191,     7,   210,    23,  4701,    26,     9,\n",
              "            208, 27975,     6,    96,  1649,  7576,  1054,  3246,     6,    44,\n",
              "            709,    30,     8,   403,  6174,  2936,  5333,    13,  4425, 14128,\n",
              "           3690,   469,     6,   754,  2516,     8,  2827,   535,   216,   856,\n",
              "           1380,  5073,    23,    12,   817,     8,   151,    38,    12,   116,\n",
              "              3,    88,    56,   456,  4432,    13,   112,  5492,  5712,    13,\n",
              "           1260,  2476,    12,   192, 23095,  4192,     7,   334,   215,     5,\n",
              "              1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-u4Zg-i3CGH",
        "outputId": "39ac8f6c-7693-4260-fef5-7c8c7eac4964"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source_ids': tensor([[21603,    10,   749,  ...,     0,     0,     0],\n",
              "         [21603,    10,    37,  ...,     0,     0,     0]]),\n",
              " 'source_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
              " 'target_ids': tensor([[  749,  4377,    53,   581,     8,  4816,   993,    16,  1025,    18,\n",
              "           8071,   958,  3331,     6,  4968,  1689,  2713,   640,  2315,   708,\n",
              "             46,    16, 14339,  6585,    45,  1856,     5,    96,   634,  2870,\n",
              "             21,  4831,    57,  4072,   277,    13,  1547,    56,   916,  6501,\n",
              "             27, 10255,  9822,  7211,     7,   165,  6384,    12,  1025,  1088,\n",
              "            958,  3331,  8598,   976,     3,     9,  4072,  7221,    31,     7,\n",
              "           6028,   243,     5,    37,  6585,    19,   952,    12, 23773,     8,\n",
              "           4471,    13, 27592,     5,     1,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [   37, 17600,  3684,  5205,    41,  4547,   371,    61,    65,     3,\n",
              "          27217,  9901,     3,    58,  8630,  3358,  1494,     3,    58,   357,\n",
              "          27880,    45,  1244, 20008,    31,     7,  2148,    26,     9,  3939,\n",
              "              5,   100,   639,   227,     8,   272,  7016, 10195,     3,     9,\n",
              "           9901,  7481,  7782,    15,    17,    15,    49,     6,  4313,    38,\n",
              "            412,  1635,  5186,    76,  1824,     6,    45,  4004,   459,   288,\n",
              "           3791,  4947,    91,  5950,    16,  2148,    26,     9,     5,    37,\n",
              "           2095,  1413,  3822,   920,   376,    11,     3,    88,  4862,   135,\n",
              "             24,     8,  1929,    13,  9901,  3358,    45, 19039,    47,  5018,\n",
              "             21,  1480,  2818,   706,     5,     1,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "next(iter(val_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHs0l9hW6nb1"
      },
      "source": [
        "<h1>TF MODEL</h1>\n",
        "<img src=\"./content/drive/MyDrive/news_summary/tf.png\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LhSiN26f3GdV"
      },
      "outputs": [],
      "source": [
        "def train_model(epoch, tokenizer, model, device, data_loader, optimizer):\n",
        "  model.train(mode=True)\n",
        "  for _, data in enumerate(data_loader):\n",
        "    y = data['target_ids'].to(device, dtype=torch.long)\n",
        "    y_ids = y[:, :-1].contiguous() # skipping the last word for the decoder model, copying the tensors n memory\n",
        "    labels = y[:, 1:].clone().detach() # actual targets\n",
        "    labels[y[:,1:] == tokenizer.pad_token_id] = -100 # setting the pad id 0 as -100 so that it skips model training\n",
        "    ids = data['source_ids'].to(device, dtype=torch.long)\n",
        "    masks = data['source_mask'].to(device, dtype=torch.long)\n",
        "\n",
        "    outputs = model(input_ids=ids, attention_mask=masks, decoder_input_ids=y_ids, labels=labels)\n",
        "    loss = outputs[0]\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(f'Train loss: {loss.item()} at epoch {epoch}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qqQPbixW5M0B"
      },
      "outputs": [],
      "source": [
        "def val_model(epoch, tokenize, model, device, data_loader):\n",
        "  model.train(mode=False)\n",
        "  predictions, txts = [], []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for _, data in enumerate(data_loader):\n",
        "      y = data['target_ids'].to(device, dtype=torch.long)\n",
        "      ids = data['source_ids'].to(device, dtype=torch.long)\n",
        "      mask = data['source_mask'].to(device, dtype=torch.long)\n",
        "\n",
        "      # num of beams = 4, prob of 4 words\n",
        "      pred_ids = model.generate(input_ids=ids, \n",
        "                                attention_mask=mask, \n",
        "                                max_length=250, \n",
        "                                num_beams=4, \n",
        "                                repetition_penalty=2.0, \n",
        "                                length_penalty=1.0, \n",
        "                                early_stopping=True)\n",
        "      \n",
        "      preds = [tokenize.decode(id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for id in pred_ids]\n",
        "      target = [tokenize.decode(id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for id in y]\n",
        "\n",
        "      predictions.extend(preds)\n",
        "      txts.extend(target)\n",
        "\n",
        "  return predictions, txts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fc4hWajM8L-V"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(Config.SEED) # pytorch random seed\n",
        "np.random.seed(Config.SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d69fb25d3222405da276d4428342f24e",
            "82aa212ead654d3fa535d55a1da1e7e1",
            "36fb1ecbea9849769a8a8b53a0c9c2b7",
            "349d91e5385e4edc842f8ebdf41b5ce0",
            "6901f05fda3d4b8da51610cc05afd96b",
            "0f676d1c2f4b4de8acf36d0420a9272b",
            "1ae84d3d149f4cc38113c4138acb20bb",
            "e456154efc584a89bb2e16e09fd37e93",
            "22bb946dfec24863a2368b02bbd0efb5",
            "51d88f0a8540455ca6f3f324809c2c5a",
            "efba70ee9b7445e899526167d6a0f181",
            "172e3848b22a4d0b932e91d48167f022",
            "9d295708685f45cfa59abbeddfd9605f",
            "56cec9bdf9a546f19f43143b82a60361",
            "6a77c83804a441059c59aa42f45ec415",
            "96c4c2e41e3a4231861ab1794fea2a34",
            "5e8fb326afdf4bef853e70e2576d7aee",
            "08b4c8ad052a4744a86c0bd4636e44a0",
            "e75876423db342b598853f40e5306589",
            "dd15b7a9b8a94177ba7e90cc5861533d",
            "312b31c648be4880832670bd2940da0f",
            "26fa51bd6d35490f971aaf7d5be7199d"
          ]
        },
        "id": "OVtLzv6v8WDE",
        "outputId": "a8de2d39-efb8-452f-9591-d0481f994078"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d69fb25d3222405da276d4428342f24e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "172e3848b22a4d0b932e91d48167f022"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum([p.numel() for p in model.parameters() if p.requires_grad])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isWi-lmKnhj8",
        "outputId": "92866fe7-e180-451b-efc9-a75758eac595"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60506624"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dRnbG-5q8ga8"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=Config.LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVzBa9-584B2",
        "outputId": "8fbb40a5-87d0-4da0-fd29-e230b225c241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 3.4926369190216064 at epoch 0\n",
            "Train loss: 2.479726791381836 at epoch 0\n",
            "Train loss: 3.0086302757263184 at epoch 0\n",
            "Train loss: 2.7178070545196533 at epoch 0\n",
            "Train loss: 2.0589842796325684 at epoch 0\n",
            "Train loss: 1.5570931434631348 at epoch 0\n",
            "Train loss: 2.665304660797119 at epoch 0\n",
            "Train loss: 1.8471661806106567 at epoch 0\n",
            "Train loss: 2.8488986492156982 at epoch 0\n",
            "Train loss: 2.4013192653656006 at epoch 0\n",
            "Train loss: 1.6186436414718628 at epoch 0\n",
            "Train loss: 1.8609271049499512 at epoch 0\n",
            "Train loss: 2.2892589569091797 at epoch 0\n",
            "Train loss: 2.8826003074645996 at epoch 0\n",
            "Train loss: 5.155247211456299 at epoch 0\n",
            "Train loss: 4.80718994140625 at epoch 0\n",
            "Train loss: 1.4876031875610352 at epoch 0\n",
            "Train loss: 2.3890769481658936 at epoch 0\n",
            "Train loss: 4.227201461791992 at epoch 0\n",
            "Train loss: 2.0078506469726562 at epoch 0\n",
            "Train loss: 1.8181449174880981 at epoch 0\n",
            "Train loss: 2.3403170108795166 at epoch 0\n",
            "Train loss: 1.8728511333465576 at epoch 0\n",
            "Train loss: 2.4775326251983643 at epoch 0\n",
            "Train loss: 2.824907064437866 at epoch 0\n",
            "Train loss: 3.3593485355377197 at epoch 0\n",
            "Train loss: 1.8301690816879272 at epoch 0\n",
            "Train loss: 2.0121517181396484 at epoch 0\n",
            "Train loss: 2.029942750930786 at epoch 0\n",
            "Train loss: 3.063931703567505 at epoch 0\n",
            "Train loss: 2.3992505073547363 at epoch 0\n",
            "Train loss: 2.8014230728149414 at epoch 0\n",
            "Train loss: 1.612720251083374 at epoch 0\n",
            "Train loss: 2.2885029315948486 at epoch 0\n",
            "Train loss: 2.365424156188965 at epoch 0\n",
            "Train loss: 4.045149803161621 at epoch 0\n",
            "Train loss: 3.6317131519317627 at epoch 0\n",
            "Train loss: 2.760432720184326 at epoch 0\n",
            "Train loss: 1.8842577934265137 at epoch 0\n",
            "Train loss: 1.3715150356292725 at epoch 0\n",
            "Train loss: 2.518523931503296 at epoch 0\n",
            "Train loss: 2.180837631225586 at epoch 0\n",
            "Train loss: 2.562973976135254 at epoch 0\n",
            "Train loss: 2.390249013900757 at epoch 0\n",
            "Train loss: 1.7677664756774902 at epoch 0\n",
            "Train loss: 2.1483635902404785 at epoch 0\n",
            "Train loss: 1.7121771574020386 at epoch 0\n",
            "Train loss: 1.6130911111831665 at epoch 0\n",
            "Train loss: 2.3690905570983887 at epoch 0\n",
            "Train loss: 2.2997193336486816 at epoch 0\n",
            "Train loss: 4.239994525909424 at epoch 0\n",
            "Train loss: 3.623074531555176 at epoch 0\n",
            "Train loss: 2.7745919227600098 at epoch 0\n",
            "Train loss: 1.8873952627182007 at epoch 0\n",
            "Train loss: 3.1156046390533447 at epoch 0\n",
            "Train loss: 1.5242946147918701 at epoch 0\n",
            "Train loss: 2.5389230251312256 at epoch 0\n",
            "Train loss: 2.144791603088379 at epoch 0\n",
            "Train loss: 2.522186517715454 at epoch 0\n",
            "Train loss: 1.7212215662002563 at epoch 0\n",
            "Train loss: 2.347538948059082 at epoch 0\n",
            "Train loss: 1.9648938179016113 at epoch 0\n",
            "Train loss: 1.996146559715271 at epoch 0\n",
            "Train loss: 3.405566930770874 at epoch 0\n",
            "Train loss: 2.661987781524658 at epoch 0\n",
            "Train loss: 1.7696622610092163 at epoch 0\n",
            "Train loss: 1.6582705974578857 at epoch 0\n",
            "Train loss: 2.3706984519958496 at epoch 0\n",
            "Train loss: 2.231518030166626 at epoch 0\n",
            "Train loss: 3.873358964920044 at epoch 0\n",
            "Train loss: 2.8688108921051025 at epoch 0\n",
            "Train loss: 1.8804271221160889 at epoch 0\n",
            "Train loss: 3.958434820175171 at epoch 0\n",
            "Train loss: 3.959258794784546 at epoch 0\n",
            "Train loss: 2.3677926063537598 at epoch 0\n",
            "Train loss: 1.3647540807724 at epoch 0\n",
            "Train loss: 3.1660358905792236 at epoch 0\n",
            "Train loss: 4.075798034667969 at epoch 0\n",
            "Train loss: 1.7215012311935425 at epoch 0\n",
            "Train loss: 1.5178972482681274 at epoch 0\n",
            "Train loss: 2.4736056327819824 at epoch 0\n",
            "Train loss: 1.860154151916504 at epoch 0\n",
            "Train loss: 1.71694815158844 at epoch 0\n",
            "Train loss: 3.436372995376587 at epoch 0\n",
            "Train loss: 2.5398709774017334 at epoch 0\n",
            "Train loss: 2.213855266571045 at epoch 0\n",
            "Train loss: 2.2430686950683594 at epoch 0\n",
            "Train loss: 2.2269232273101807 at epoch 0\n",
            "Train loss: 3.7580974102020264 at epoch 0\n",
            "Train loss: 2.4441444873809814 at epoch 0\n",
            "Train loss: 1.8289272785186768 at epoch 0\n",
            "Train loss: 2.595949649810791 at epoch 0\n",
            "Train loss: 1.5044838190078735 at epoch 0\n",
            "Train loss: 1.964260220527649 at epoch 0\n",
            "Train loss: 2.7021267414093018 at epoch 0\n",
            "Train loss: 1.6430912017822266 at epoch 0\n",
            "Train loss: 1.9925639629364014 at epoch 0\n",
            "Train loss: 2.4322688579559326 at epoch 0\n",
            "Train loss: 2.285395860671997 at epoch 0\n",
            "Train loss: 1.8415895700454712 at epoch 0\n",
            "Train loss: 2.6079444885253906 at epoch 0\n",
            "Train loss: 2.6773412227630615 at epoch 0\n",
            "Train loss: 1.505012035369873 at epoch 0\n",
            "Train loss: 2.4656686782836914 at epoch 0\n",
            "Train loss: 2.1199889183044434 at epoch 0\n",
            "Train loss: 2.5053188800811768 at epoch 0\n",
            "Train loss: 1.8526087999343872 at epoch 0\n",
            "Train loss: 2.1028387546539307 at epoch 0\n",
            "Train loss: 2.155640125274658 at epoch 0\n",
            "Train loss: 2.0339746475219727 at epoch 0\n",
            "Train loss: 2.4006705284118652 at epoch 0\n",
            "Train loss: 2.203794002532959 at epoch 0\n",
            "Train loss: 2.105731964111328 at epoch 0\n",
            "Train loss: 2.3914177417755127 at epoch 0\n",
            "Train loss: 1.317803978919983 at epoch 0\n",
            "Train loss: 2.331831693649292 at epoch 0\n",
            "Train loss: 4.139890670776367 at epoch 0\n",
            "Train loss: 3.030409812927246 at epoch 0\n",
            "Train loss: 1.9363725185394287 at epoch 0\n",
            "Train loss: 1.7612755298614502 at epoch 0\n",
            "Train loss: 2.166242837905884 at epoch 0\n",
            "Train loss: 2.1344199180603027 at epoch 0\n",
            "Train loss: 2.536456346511841 at epoch 0\n",
            "Train loss: 2.7690415382385254 at epoch 0\n",
            "Train loss: 3.488539457321167 at epoch 0\n",
            "Train loss: 2.490438938140869 at epoch 0\n",
            "Train loss: 2.110520124435425 at epoch 0\n",
            "Train loss: 2.5792458057403564 at epoch 0\n",
            "Train loss: 1.9763330221176147 at epoch 0\n",
            "Train loss: 1.9517884254455566 at epoch 0\n",
            "Train loss: 1.9883301258087158 at epoch 0\n",
            "Train loss: 2.737837553024292 at epoch 0\n",
            "Train loss: 2.029330015182495 at epoch 0\n",
            "Train loss: 3.1675405502319336 at epoch 0\n",
            "Train loss: 1.9121248722076416 at epoch 0\n",
            "Train loss: 1.8047298192977905 at epoch 0\n",
            "Train loss: 1.8516877889633179 at epoch 0\n",
            "Train loss: 2.239091396331787 at epoch 0\n",
            "Train loss: 2.375828504562378 at epoch 0\n",
            "Train loss: 2.4500949382781982 at epoch 0\n",
            "Train loss: 1.8090543746948242 at epoch 0\n",
            "Train loss: 1.3241779804229736 at epoch 0\n",
            "Train loss: 2.2248568534851074 at epoch 0\n",
            "Train loss: 2.230372428894043 at epoch 0\n",
            "Train loss: 1.9863828420639038 at epoch 0\n",
            "Train loss: 1.1761099100112915 at epoch 0\n",
            "Train loss: 1.972425937652588 at epoch 0\n",
            "Train loss: 1.2052494287490845 at epoch 0\n",
            "Train loss: 3.719395875930786 at epoch 0\n",
            "Train loss: 2.4012980461120605 at epoch 0\n",
            "Train loss: 1.4610402584075928 at epoch 0\n",
            "Train loss: 2.6115760803222656 at epoch 0\n",
            "Train loss: 3.5759658813476562 at epoch 0\n",
            "Train loss: 2.8818631172180176 at epoch 0\n",
            "Train loss: 2.095186948776245 at epoch 0\n",
            "Train loss: 1.8536787033081055 at epoch 0\n",
            "Train loss: 2.902794361114502 at epoch 0\n",
            "Train loss: 1.8903532028198242 at epoch 0\n",
            "Train loss: 1.5124714374542236 at epoch 0\n",
            "Train loss: 2.1431171894073486 at epoch 0\n",
            "Train loss: 2.0730464458465576 at epoch 0\n",
            "Train loss: 2.274097442626953 at epoch 0\n",
            "Train loss: 1.5580581426620483 at epoch 0\n",
            "Train loss: 2.995985746383667 at epoch 0\n",
            "Train loss: 1.9105143547058105 at epoch 0\n",
            "Train loss: 3.95383882522583 at epoch 0\n",
            "Train loss: 2.5012309551239014 at epoch 0\n",
            "Train loss: 2.0793569087982178 at epoch 0\n",
            "Train loss: 2.7678675651550293 at epoch 0\n",
            "Train loss: 2.408416748046875 at epoch 0\n",
            "Train loss: 1.8357658386230469 at epoch 0\n",
            "Train loss: 2.618851900100708 at epoch 0\n",
            "Train loss: 2.8661224842071533 at epoch 0\n",
            "Train loss: 1.7172653675079346 at epoch 0\n",
            "Train loss: 1.5733084678649902 at epoch 0\n",
            "Train loss: 2.3513050079345703 at epoch 0\n",
            "Train loss: 2.6461918354034424 at epoch 0\n",
            "Train loss: 2.3047304153442383 at epoch 0\n",
            "Train loss: 2.120439291000366 at epoch 0\n",
            "Train loss: 3.2788052558898926 at epoch 0\n",
            "Train loss: 2.6005780696868896 at epoch 0\n",
            "Train loss: 2.1363446712493896 at epoch 0\n",
            "Train loss: 2.477747917175293 at epoch 0\n",
            "Train loss: 1.2869592905044556 at epoch 0\n",
            "Train loss: 1.8117215633392334 at epoch 0\n",
            "Train loss: 3.051888942718506 at epoch 0\n",
            "Train loss: 2.3426358699798584 at epoch 0\n",
            "Train loss: 2.417539596557617 at epoch 0\n",
            "Train loss: 1.9330499172210693 at epoch 0\n",
            "Train loss: 2.108893871307373 at epoch 0\n",
            "Train loss: 2.6328210830688477 at epoch 0\n",
            "Train loss: 2.4677202701568604 at epoch 0\n",
            "Train loss: 2.578016996383667 at epoch 0\n",
            "Train loss: 1.6202248334884644 at epoch 0\n",
            "Train loss: 3.5886707305908203 at epoch 0\n",
            "Train loss: 2.447200298309326 at epoch 0\n",
            "Train loss: 1.3720602989196777 at epoch 0\n",
            "Train loss: 2.799246072769165 at epoch 0\n",
            "Train loss: 1.339257836341858 at epoch 0\n",
            "Train loss: 2.5939505100250244 at epoch 0\n",
            "Train loss: 1.486701488494873 at epoch 0\n",
            "Train loss: 2.2240426540374756 at epoch 0\n",
            "Train loss: 2.000821352005005 at epoch 0\n",
            "Train loss: 2.5553808212280273 at epoch 0\n",
            "Train loss: 2.347093343734741 at epoch 0\n",
            "Train loss: 3.0042688846588135 at epoch 0\n",
            "Train loss: 3.581293821334839 at epoch 0\n",
            "Train loss: 1.6802239418029785 at epoch 0\n",
            "Train loss: 2.066535234451294 at epoch 0\n",
            "Train loss: 2.5324790477752686 at epoch 0\n",
            "Train loss: 2.8297507762908936 at epoch 0\n",
            "Train loss: 2.133557081222534 at epoch 0\n",
            "Train loss: 2.842470407485962 at epoch 0\n",
            "Train loss: 1.3077876567840576 at epoch 0\n",
            "Train loss: 2.9710915088653564 at epoch 0\n",
            "Train loss: 3.0933926105499268 at epoch 0\n",
            "Train loss: 1.6904438734054565 at epoch 0\n",
            "Train loss: 2.5222246646881104 at epoch 0\n",
            "Train loss: 3.211796522140503 at epoch 0\n",
            "Train loss: 1.8283580541610718 at epoch 0\n",
            "Train loss: 2.3424785137176514 at epoch 0\n",
            "Train loss: 1.8092859983444214 at epoch 0\n",
            "Train loss: 1.427301287651062 at epoch 0\n",
            "Train loss: 1.826759934425354 at epoch 0\n",
            "Train loss: 1.9649977684020996 at epoch 0\n",
            "Train loss: 2.3042619228363037 at epoch 0\n",
            "Train loss: 2.482252597808838 at epoch 0\n",
            "Train loss: 1.8953717947006226 at epoch 0\n",
            "Train loss: 2.3535830974578857 at epoch 0\n",
            "Train loss: 2.062412977218628 at epoch 0\n",
            "Train loss: 2.253068685531616 at epoch 0\n",
            "Train loss: 2.624073028564453 at epoch 0\n",
            "Train loss: 1.810816764831543 at epoch 0\n",
            "Train loss: 2.2850046157836914 at epoch 0\n",
            "Train loss: 2.8424270153045654 at epoch 0\n",
            "Train loss: 2.8663928508758545 at epoch 0\n",
            "Train loss: 2.9576659202575684 at epoch 0\n",
            "Train loss: 2.5647170543670654 at epoch 0\n",
            "Train loss: 2.4304094314575195 at epoch 0\n",
            "Train loss: 2.5903568267822266 at epoch 0\n",
            "Train loss: 2.3670477867126465 at epoch 0\n",
            "Train loss: 2.8664815425872803 at epoch 0\n",
            "Train loss: 2.1430132389068604 at epoch 0\n",
            "Train loss: 1.6804262399673462 at epoch 0\n",
            "Train loss: 2.4196054935455322 at epoch 0\n",
            "Train loss: 3.3945815563201904 at epoch 0\n",
            "Train loss: 1.8361570835113525 at epoch 0\n",
            "Train loss: 2.5505008697509766 at epoch 0\n",
            "Train loss: 2.707895517349243 at epoch 0\n",
            "Train loss: 2.2288718223571777 at epoch 0\n",
            "Train loss: 3.196298599243164 at epoch 0\n",
            "Train loss: 2.460942029953003 at epoch 0\n",
            "Train loss: 2.415476083755493 at epoch 0\n",
            "Train loss: 2.301161766052246 at epoch 0\n",
            "Train loss: 2.204146146774292 at epoch 0\n",
            "Train loss: 2.5445244312286377 at epoch 0\n",
            "Train loss: 2.4028520584106445 at epoch 0\n",
            "Train loss: 2.5367517471313477 at epoch 0\n",
            "Train loss: 2.8686749935150146 at epoch 0\n",
            "Train loss: 1.7861329317092896 at epoch 0\n",
            "Train loss: 1.464147686958313 at epoch 0\n",
            "Train loss: 2.127610206604004 at epoch 0\n",
            "Train loss: 2.982226848602295 at epoch 0\n",
            "Train loss: 2.0654892921447754 at epoch 0\n",
            "Train loss: 2.6910400390625 at epoch 0\n",
            "Train loss: 1.58830988407135 at epoch 0\n",
            "Train loss: 2.52485990524292 at epoch 0\n",
            "Train loss: 2.077800750732422 at epoch 0\n",
            "Train loss: 2.133613348007202 at epoch 0\n",
            "Train loss: 2.3438994884490967 at epoch 0\n",
            "Train loss: 3.2257676124572754 at epoch 0\n",
            "Train loss: 3.9871304035186768 at epoch 0\n",
            "Train loss: 3.2055277824401855 at epoch 0\n",
            "Train loss: 1.7620397806167603 at epoch 0\n",
            "Train loss: 1.5777612924575806 at epoch 0\n",
            "Train loss: 2.950536012649536 at epoch 0\n",
            "Train loss: 2.7163968086242676 at epoch 0\n",
            "Train loss: 2.2652039527893066 at epoch 0\n",
            "Train loss: 3.1509482860565186 at epoch 0\n",
            "Train loss: 1.3310041427612305 at epoch 0\n",
            "Train loss: 2.3646130561828613 at epoch 0\n",
            "Train loss: 1.4636845588684082 at epoch 0\n",
            "Train loss: 1.502878189086914 at epoch 0\n",
            "Train loss: 2.7111611366271973 at epoch 0\n",
            "Train loss: 1.8516789674758911 at epoch 0\n",
            "Train loss: 3.4393584728240967 at epoch 0\n",
            "Train loss: 2.339843273162842 at epoch 0\n",
            "Train loss: 1.8584051132202148 at epoch 0\n",
            "Train loss: 1.9852633476257324 at epoch 0\n",
            "Train loss: 2.2494912147521973 at epoch 0\n",
            "Train loss: 1.8801729679107666 at epoch 0\n",
            "Train loss: 1.3920998573303223 at epoch 0\n",
            "Train loss: 3.576096296310425 at epoch 0\n",
            "Train loss: 1.59712553024292 at epoch 0\n",
            "Train loss: 2.939047336578369 at epoch 0\n",
            "Train loss: 1.675478219985962 at epoch 0\n",
            "Train loss: 2.1965553760528564 at epoch 0\n",
            "Train loss: 2.2199487686157227 at epoch 0\n",
            "Train loss: 2.1874823570251465 at epoch 0\n",
            "Train loss: 1.7311581373214722 at epoch 0\n",
            "Train loss: 2.265522003173828 at epoch 0\n",
            "Train loss: 2.260923147201538 at epoch 0\n",
            "Train loss: 1.784360408782959 at epoch 0\n",
            "Train loss: 2.190152168273926 at epoch 0\n",
            "Train loss: 3.1374728679656982 at epoch 0\n",
            "Train loss: 3.1770763397216797 at epoch 0\n",
            "Train loss: 2.079983949661255 at epoch 0\n",
            "Train loss: 2.262937307357788 at epoch 0\n",
            "Train loss: 2.2857587337493896 at epoch 0\n",
            "Train loss: 1.8218419551849365 at epoch 0\n",
            "Train loss: 3.070952892303467 at epoch 0\n",
            "Train loss: 3.040354013442993 at epoch 0\n",
            "Train loss: 3.348238468170166 at epoch 0\n",
            "Train loss: 2.6704111099243164 at epoch 0\n",
            "Train loss: 2.835530996322632 at epoch 0\n",
            "Train loss: 2.4079391956329346 at epoch 0\n",
            "Train loss: 3.1256232261657715 at epoch 0\n",
            "Train loss: 2.7288260459899902 at epoch 0\n",
            "Train loss: 2.4418861865997314 at epoch 0\n",
            "Train loss: 2.120292901992798 at epoch 0\n",
            "Train loss: 2.6004295349121094 at epoch 0\n",
            "Train loss: 2.5676190853118896 at epoch 0\n",
            "Train loss: 2.9219698905944824 at epoch 0\n",
            "Train loss: 2.457005739212036 at epoch 0\n",
            "Train loss: 1.5582367181777954 at epoch 0\n",
            "Train loss: 2.3357930183410645 at epoch 0\n",
            "Train loss: 3.4850668907165527 at epoch 0\n",
            "Train loss: 2.1523020267486572 at epoch 0\n",
            "Train loss: 2.2150156497955322 at epoch 0\n",
            "Train loss: 1.9999396800994873 at epoch 0\n",
            "Train loss: 2.2694356441497803 at epoch 0\n",
            "Train loss: 2.3753764629364014 at epoch 0\n",
            "Train loss: 2.652862071990967 at epoch 0\n",
            "Train loss: 2.187718629837036 at epoch 0\n",
            "Train loss: 1.969531774520874 at epoch 0\n",
            "Train loss: 2.0501911640167236 at epoch 0\n",
            "Train loss: 2.067667007446289 at epoch 0\n",
            "Train loss: 2.6179206371307373 at epoch 0\n",
            "Train loss: 2.4114909172058105 at epoch 0\n",
            "Train loss: 2.3501596450805664 at epoch 0\n",
            "Train loss: 1.455956220626831 at epoch 0\n",
            "Train loss: 1.9867323637008667 at epoch 0\n",
            "Train loss: 2.1933908462524414 at epoch 0\n",
            "Train loss: 2.5351035594940186 at epoch 0\n",
            "Train loss: 2.2955210208892822 at epoch 0\n",
            "Train loss: 2.336625337600708 at epoch 0\n",
            "Train loss: 2.439258337020874 at epoch 0\n",
            "Train loss: 2.815904378890991 at epoch 0\n",
            "Train loss: 2.3673760890960693 at epoch 0\n",
            "Train loss: 1.6986638307571411 at epoch 0\n",
            "Train loss: 2.671602725982666 at epoch 0\n",
            "Train loss: 1.3858678340911865 at epoch 0\n",
            "Train loss: 1.8578872680664062 at epoch 0\n",
            "Train loss: 2.2963011264801025 at epoch 0\n",
            "Train loss: 3.1282095909118652 at epoch 0\n",
            "Train loss: 2.064448595046997 at epoch 0\n",
            "Train loss: 2.7089688777923584 at epoch 0\n",
            "Train loss: 1.3344697952270508 at epoch 0\n",
            "Train loss: 2.979559898376465 at epoch 0\n",
            "Train loss: 3.119473695755005 at epoch 0\n",
            "Train loss: 3.2681667804718018 at epoch 0\n",
            "Train loss: 2.3907854557037354 at epoch 0\n",
            "Train loss: 3.0346462726593018 at epoch 0\n",
            "Train loss: 1.6935057640075684 at epoch 0\n",
            "Train loss: 2.2072103023529053 at epoch 0\n",
            "Train loss: 1.832614541053772 at epoch 0\n",
            "Train loss: 2.137770891189575 at epoch 0\n",
            "Train loss: 3.8128769397735596 at epoch 0\n",
            "Train loss: 2.268789291381836 at epoch 0\n",
            "Train loss: 2.11549973487854 at epoch 0\n",
            "Train loss: 3.356659173965454 at epoch 0\n",
            "Train loss: 2.4522135257720947 at epoch 0\n",
            "Train loss: 2.323237180709839 at epoch 0\n",
            "Train loss: 2.2546820640563965 at epoch 0\n",
            "Train loss: 2.532731294631958 at epoch 0\n",
            "Train loss: 2.328826904296875 at epoch 0\n",
            "Train loss: 2.644766330718994 at epoch 0\n",
            "Train loss: 2.3456015586853027 at epoch 0\n",
            "Train loss: 2.900157928466797 at epoch 0\n",
            "Train loss: 1.7838187217712402 at epoch 0\n",
            "Train loss: 3.4505398273468018 at epoch 0\n",
            "Train loss: 1.7300976514816284 at epoch 0\n",
            "Train loss: 2.3878023624420166 at epoch 0\n",
            "Train loss: 2.8651340007781982 at epoch 0\n",
            "Train loss: 2.6944453716278076 at epoch 0\n",
            "Train loss: 2.011683940887451 at epoch 0\n",
            "Train loss: 2.3834292888641357 at epoch 0\n",
            "Train loss: 2.2027981281280518 at epoch 0\n",
            "Train loss: 2.639146327972412 at epoch 0\n",
            "Train loss: 1.5610523223876953 at epoch 0\n",
            "Train loss: 1.6680439710617065 at epoch 0\n",
            "Train loss: 3.5800867080688477 at epoch 0\n",
            "Train loss: 1.2586896419525146 at epoch 0\n",
            "Train loss: 2.067235231399536 at epoch 0\n",
            "Train loss: 1.6385443210601807 at epoch 0\n",
            "Train loss: 3.974712371826172 at epoch 0\n",
            "Train loss: 1.5149503946304321 at epoch 0\n",
            "Train loss: 2.0733368396759033 at epoch 0\n",
            "Train loss: 1.9530580043792725 at epoch 0\n",
            "Train loss: 1.8551907539367676 at epoch 0\n",
            "Train loss: 4.2852373123168945 at epoch 0\n",
            "Train loss: 2.2743616104125977 at epoch 0\n",
            "Train loss: 2.5893754959106445 at epoch 0\n",
            "Train loss: 1.5121333599090576 at epoch 0\n",
            "Train loss: 2.7362077236175537 at epoch 0\n",
            "Train loss: 1.999407172203064 at epoch 0\n",
            "Train loss: 1.416213035583496 at epoch 0\n",
            "Train loss: 2.428004264831543 at epoch 0\n",
            "Train loss: 3.3521761894226074 at epoch 0\n",
            "Train loss: 1.865543007850647 at epoch 0\n",
            "Train loss: 2.5687918663024902 at epoch 0\n",
            "Train loss: 2.1531777381896973 at epoch 0\n",
            "Train loss: 1.2883893251419067 at epoch 0\n",
            "Train loss: 2.8676252365112305 at epoch 0\n",
            "Train loss: 2.2974207401275635 at epoch 0\n",
            "Train loss: 2.1341803073883057 at epoch 0\n",
            "Train loss: 3.430992364883423 at epoch 0\n",
            "Train loss: 2.3029658794403076 at epoch 0\n",
            "Train loss: 1.9917088747024536 at epoch 0\n",
            "Train loss: 2.0426197052001953 at epoch 0\n",
            "Train loss: 2.570845365524292 at epoch 0\n",
            "Train loss: 2.280596971511841 at epoch 0\n",
            "Train loss: 1.9808599948883057 at epoch 0\n",
            "Train loss: 2.111870765686035 at epoch 0\n",
            "Train loss: 3.681278705596924 at epoch 0\n",
            "Train loss: 2.158673048019409 at epoch 0\n",
            "Train loss: 3.167494773864746 at epoch 0\n",
            "Train loss: 1.9556747674942017 at epoch 0\n",
            "Train loss: 1.7968478202819824 at epoch 0\n",
            "Train loss: 2.6091244220733643 at epoch 0\n",
            "Train loss: 1.9911353588104248 at epoch 0\n",
            "Train loss: 2.3794727325439453 at epoch 0\n",
            "Train loss: 2.191457748413086 at epoch 0\n",
            "Train loss: 2.9019603729248047 at epoch 0\n",
            "Train loss: 2.224050283432007 at epoch 0\n",
            "Train loss: 1.3412234783172607 at epoch 0\n",
            "Train loss: 1.698620319366455 at epoch 0\n",
            "Train loss: 1.4285954236984253 at epoch 0\n",
            "Train loss: 2.060610771179199 at epoch 0\n",
            "Train loss: 2.041472911834717 at epoch 0\n",
            "Train loss: 1.8062829971313477 at epoch 0\n",
            "Train loss: 2.8745498657226562 at epoch 0\n",
            "Train loss: 2.0377895832061768 at epoch 0\n",
            "Train loss: 2.2210428714752197 at epoch 0\n",
            "Train loss: 3.1804370880126953 at epoch 0\n",
            "Train loss: 1.859161376953125 at epoch 0\n",
            "Train loss: 1.212590217590332 at epoch 0\n",
            "Train loss: 2.0101637840270996 at epoch 0\n",
            "Train loss: 1.906713843345642 at epoch 0\n",
            "Train loss: 2.403920888900757 at epoch 0\n",
            "Train loss: 2.580833673477173 at epoch 0\n",
            "Train loss: 1.6197923421859741 at epoch 0\n",
            "Train loss: 2.3644700050354004 at epoch 0\n",
            "Train loss: 1.720020055770874 at epoch 0\n",
            "Train loss: 2.0107479095458984 at epoch 0\n",
            "Train loss: 1.2399252653121948 at epoch 0\n",
            "Train loss: 2.531503438949585 at epoch 0\n",
            "Train loss: 2.499220132827759 at epoch 0\n",
            "Train loss: 1.5517125129699707 at epoch 0\n",
            "Train loss: 1.8891711235046387 at epoch 0\n",
            "Train loss: 2.091850757598877 at epoch 0\n",
            "Train loss: 2.8458168506622314 at epoch 0\n",
            "Train loss: 2.509770393371582 at epoch 0\n",
            "Train loss: 1.630143165588379 at epoch 0\n",
            "Train loss: 3.433513879776001 at epoch 0\n",
            "Train loss: 2.5296478271484375 at epoch 0\n",
            "Train loss: 2.578934669494629 at epoch 0\n",
            "Train loss: 1.8990538120269775 at epoch 0\n",
            "Train loss: 2.4168357849121094 at epoch 0\n",
            "Train loss: 2.3547754287719727 at epoch 0\n",
            "Train loss: 1.8054252862930298 at epoch 0\n",
            "Train loss: 2.3089606761932373 at epoch 0\n",
            "Train loss: 1.7000254392623901 at epoch 0\n",
            "Train loss: 1.7221128940582275 at epoch 0\n",
            "Train loss: 2.5890281200408936 at epoch 0\n",
            "Train loss: 2.8424463272094727 at epoch 0\n",
            "Train loss: 1.5750677585601807 at epoch 0\n",
            "Train loss: 1.5262559652328491 at epoch 0\n",
            "Train loss: 1.8091553449630737 at epoch 0\n",
            "Train loss: 3.2906508445739746 at epoch 0\n",
            "Train loss: 2.1322875022888184 at epoch 0\n",
            "Train loss: 3.0133774280548096 at epoch 0\n",
            "Train loss: 2.631340503692627 at epoch 0\n",
            "Train loss: 2.3737618923187256 at epoch 0\n",
            "Train loss: 2.065174102783203 at epoch 0\n",
            "Train loss: 2.075270652770996 at epoch 0\n",
            "Train loss: 2.800999879837036 at epoch 0\n",
            "Train loss: 2.089128017425537 at epoch 0\n",
            "Train loss: 1.6604112386703491 at epoch 0\n",
            "Train loss: 2.8258025646209717 at epoch 0\n",
            "Train loss: 3.344024896621704 at epoch 0\n",
            "Train loss: 2.607799530029297 at epoch 0\n",
            "Train loss: 1.420864224433899 at epoch 0\n",
            "Train loss: 2.2660677433013916 at epoch 0\n",
            "Train loss: 2.7346956729888916 at epoch 0\n",
            "Train loss: 3.4024555683135986 at epoch 0\n",
            "Train loss: 2.0092248916625977 at epoch 0\n",
            "Train loss: 3.8826472759246826 at epoch 0\n",
            "Train loss: 1.3472802639007568 at epoch 0\n",
            "Train loss: 1.6380512714385986 at epoch 0\n",
            "Train loss: 3.156466484069824 at epoch 0\n",
            "Train loss: 1.8505933284759521 at epoch 0\n",
            "Train loss: 1.9167474508285522 at epoch 0\n",
            "Train loss: 1.429290533065796 at epoch 0\n",
            "Train loss: 2.4905824661254883 at epoch 0\n",
            "Train loss: 3.2007339000701904 at epoch 0\n",
            "Train loss: 1.4180362224578857 at epoch 0\n",
            "Train loss: 2.331737518310547 at epoch 0\n",
            "Train loss: 1.2087042331695557 at epoch 0\n",
            "Train loss: 2.4076263904571533 at epoch 0\n",
            "Train loss: 1.3416918516159058 at epoch 0\n",
            "Train loss: 1.972245454788208 at epoch 0\n",
            "Train loss: 1.9875094890594482 at epoch 0\n",
            "Train loss: 1.618464708328247 at epoch 0\n",
            "Train loss: 1.6347347497940063 at epoch 0\n",
            "Train loss: 1.9009274244308472 at epoch 0\n",
            "Train loss: 2.0564239025115967 at epoch 0\n",
            "Train loss: 2.616532325744629 at epoch 0\n",
            "Train loss: 1.7310304641723633 at epoch 0\n",
            "Train loss: 1.6065213680267334 at epoch 0\n",
            "Train loss: 3.1768922805786133 at epoch 0\n",
            "Train loss: 1.7294796705245972 at epoch 0\n",
            "Train loss: 2.0553629398345947 at epoch 0\n",
            "Train loss: 2.5869288444519043 at epoch 0\n",
            "Train loss: 2.5089077949523926 at epoch 0\n",
            "Train loss: 2.1227059364318848 at epoch 0\n",
            "Train loss: 1.834605097770691 at epoch 0\n",
            "Train loss: 1.5696327686309814 at epoch 0\n",
            "Train loss: 1.871407151222229 at epoch 0\n",
            "Train loss: 2.5001561641693115 at epoch 0\n",
            "Train loss: 3.0610663890838623 at epoch 0\n",
            "Train loss: 1.5424387454986572 at epoch 0\n",
            "Train loss: 2.4200611114501953 at epoch 0\n",
            "Train loss: 2.326279878616333 at epoch 0\n",
            "Train loss: 2.5785634517669678 at epoch 0\n",
            "Train loss: 2.4181971549987793 at epoch 0\n",
            "Train loss: 3.07126784324646 at epoch 0\n",
            "Train loss: 2.364469289779663 at epoch 0\n",
            "Train loss: 2.4198412895202637 at epoch 0\n",
            "Train loss: 1.8601188659667969 at epoch 0\n",
            "Train loss: 1.8701995611190796 at epoch 0\n",
            "Train loss: 2.6423983573913574 at epoch 0\n",
            "Train loss: 3.0087437629699707 at epoch 0\n",
            "Train loss: 2.136874198913574 at epoch 0\n",
            "Train loss: 1.6951501369476318 at epoch 0\n",
            "Train loss: 1.8723711967468262 at epoch 0\n",
            "Train loss: 3.037644147872925 at epoch 0\n",
            "Train loss: 2.005506753921509 at epoch 0\n",
            "Train loss: 2.74303936958313 at epoch 0\n",
            "Train loss: 1.6864548921585083 at epoch 0\n",
            "Train loss: 1.4913930892944336 at epoch 0\n",
            "Train loss: 3.7115485668182373 at epoch 0\n",
            "Train loss: 2.475898265838623 at epoch 0\n",
            "Train loss: 1.5574357509613037 at epoch 0\n",
            "Train loss: 2.0921108722686768 at epoch 0\n",
            "Train loss: 2.6518123149871826 at epoch 0\n",
            "Train loss: 1.979321002960205 at epoch 0\n",
            "Train loss: 1.894905686378479 at epoch 0\n",
            "Train loss: 2.997694969177246 at epoch 0\n",
            "Train loss: 1.9111284017562866 at epoch 0\n",
            "Train loss: 3.0549447536468506 at epoch 0\n",
            "Train loss: 3.517038106918335 at epoch 0\n",
            "Train loss: 2.202859878540039 at epoch 0\n",
            "Train loss: 2.0065064430236816 at epoch 0\n",
            "Train loss: 2.8718836307525635 at epoch 0\n",
            "Train loss: 3.9386775493621826 at epoch 0\n",
            "Train loss: 1.938295841217041 at epoch 0\n",
            "Train loss: 1.6229952573776245 at epoch 0\n",
            "Train loss: 1.9314491748809814 at epoch 0\n",
            "Train loss: 2.952054262161255 at epoch 0\n",
            "Train loss: 1.3170589208602905 at epoch 0\n",
            "Train loss: 1.4822545051574707 at epoch 0\n",
            "Train loss: 1.4215160608291626 at epoch 0\n",
            "Train loss: 1.6364681720733643 at epoch 0\n",
            "Train loss: 2.3634016513824463 at epoch 0\n",
            "Train loss: 3.6503794193267822 at epoch 0\n",
            "Train loss: 1.381311058998108 at epoch 0\n",
            "Train loss: 2.2508838176727295 at epoch 0\n",
            "Train loss: 1.9524140357971191 at epoch 0\n",
            "Train loss: 1.724190354347229 at epoch 0\n",
            "Train loss: 2.553652763366699 at epoch 0\n",
            "Train loss: 1.7925297021865845 at epoch 0\n",
            "Train loss: 1.5544754266738892 at epoch 0\n",
            "Train loss: 3.0081512928009033 at epoch 0\n",
            "Train loss: 2.1918582916259766 at epoch 0\n",
            "Train loss: 3.027970790863037 at epoch 0\n",
            "Train loss: 4.217694282531738 at epoch 0\n",
            "Train loss: 2.1140050888061523 at epoch 0\n",
            "Train loss: 2.895876169204712 at epoch 0\n",
            "Train loss: 2.2045576572418213 at epoch 0\n",
            "Train loss: 1.8756041526794434 at epoch 0\n",
            "Train loss: 2.0386550426483154 at epoch 0\n",
            "Train loss: 1.8400903940200806 at epoch 0\n",
            "Train loss: 2.0098679065704346 at epoch 0\n",
            "Train loss: 2.7534565925598145 at epoch 0\n",
            "Train loss: 3.132126569747925 at epoch 0\n",
            "Train loss: 1.9172017574310303 at epoch 0\n",
            "Train loss: 1.4272938966751099 at epoch 0\n",
            "Train loss: 1.3940725326538086 at epoch 0\n",
            "Train loss: 1.915930151939392 at epoch 0\n",
            "Train loss: 1.283643126487732 at epoch 0\n",
            "Train loss: 2.2111172676086426 at epoch 0\n",
            "Train loss: 2.5207393169403076 at epoch 0\n",
            "Train loss: 3.134350299835205 at epoch 0\n",
            "Train loss: 1.5211570262908936 at epoch 0\n",
            "Train loss: 3.8125154972076416 at epoch 0\n",
            "Train loss: 2.109649181365967 at epoch 0\n",
            "Train loss: 2.047125816345215 at epoch 0\n",
            "Train loss: 2.511937141418457 at epoch 0\n",
            "Train loss: 2.6675620079040527 at epoch 0\n",
            "Train loss: 1.3299235105514526 at epoch 0\n",
            "Train loss: 1.8832496404647827 at epoch 0\n",
            "Train loss: 1.5131993293762207 at epoch 0\n",
            "Train loss: 3.5978448390960693 at epoch 0\n",
            "Train loss: 2.1965408325195312 at epoch 0\n",
            "Train loss: 2.155073404312134 at epoch 0\n",
            "Train loss: 2.4670071601867676 at epoch 0\n",
            "Train loss: 1.6842591762542725 at epoch 0\n",
            "Train loss: 2.877134323120117 at epoch 0\n",
            "Train loss: 1.489190697669983 at epoch 0\n",
            "Train loss: 2.4523203372955322 at epoch 0\n",
            "Train loss: 2.494994878768921 at epoch 0\n",
            "Train loss: 2.4790613651275635 at epoch 0\n",
            "Train loss: 1.5491588115692139 at epoch 0\n",
            "Train loss: 2.782768487930298 at epoch 0\n",
            "Train loss: 1.5501930713653564 at epoch 0\n",
            "Train loss: 2.1863248348236084 at epoch 0\n",
            "Train loss: 2.122119188308716 at epoch 0\n",
            "Train loss: 1.5524684190750122 at epoch 0\n",
            "Train loss: 2.931623935699463 at epoch 0\n",
            "Train loss: 1.7835848331451416 at epoch 0\n",
            "Train loss: 3.510014533996582 at epoch 0\n",
            "Train loss: 1.307228922843933 at epoch 0\n",
            "Train loss: 1.7996070384979248 at epoch 0\n",
            "Train loss: 2.4464197158813477 at epoch 0\n",
            "Train loss: 4.072982311248779 at epoch 0\n",
            "Train loss: 3.2205960750579834 at epoch 0\n",
            "Train loss: 1.9768445491790771 at epoch 0\n",
            "Train loss: 3.146188974380493 at epoch 0\n",
            "Train loss: 1.6837941408157349 at epoch 0\n",
            "Train loss: 2.17144513130188 at epoch 0\n",
            "Train loss: 2.4912540912628174 at epoch 0\n",
            "Train loss: 2.4445130825042725 at epoch 0\n",
            "Train loss: 1.4708870649337769 at epoch 0\n",
            "Train loss: 1.513454794883728 at epoch 0\n",
            "Train loss: 1.845103144645691 at epoch 0\n",
            "Train loss: 2.6540470123291016 at epoch 0\n",
            "Train loss: 1.9664393663406372 at epoch 0\n",
            "Train loss: 2.590778112411499 at epoch 0\n",
            "Train loss: 2.1675808429718018 at epoch 0\n",
            "Train loss: 1.3679507970809937 at epoch 0\n",
            "Train loss: 2.729825019836426 at epoch 0\n",
            "Train loss: 2.0429136753082275 at epoch 0\n",
            "Train loss: 2.702495574951172 at epoch 0\n",
            "Train loss: 1.7743240594863892 at epoch 0\n",
            "Train loss: 1.8425754308700562 at epoch 0\n",
            "Train loss: 1.6183280944824219 at epoch 0\n",
            "Train loss: 3.1390652656555176 at epoch 0\n",
            "Train loss: 2.154914617538452 at epoch 0\n",
            "Train loss: 1.8089985847473145 at epoch 0\n",
            "Train loss: 2.281761646270752 at epoch 0\n",
            "Train loss: 2.3457703590393066 at epoch 0\n",
            "Train loss: 3.678121328353882 at epoch 0\n",
            "Train loss: 1.1795639991760254 at epoch 0\n",
            "Train loss: 2.4404850006103516 at epoch 0\n",
            "Train loss: 1.38999342918396 at epoch 0\n",
            "Train loss: 2.133840560913086 at epoch 0\n",
            "Train loss: 2.6043272018432617 at epoch 0\n",
            "Train loss: 1.833436131477356 at epoch 0\n",
            "Train loss: 2.3668925762176514 at epoch 0\n",
            "Train loss: 3.7792232036590576 at epoch 0\n",
            "Train loss: 2.1224405765533447 at epoch 0\n",
            "Train loss: 2.4096336364746094 at epoch 0\n",
            "Train loss: 2.1069161891937256 at epoch 0\n",
            "Train loss: 2.406202554702759 at epoch 0\n",
            "Train loss: 1.3496848344802856 at epoch 0\n",
            "Train loss: 1.595399260520935 at epoch 0\n",
            "Train loss: 2.0153253078460693 at epoch 0\n",
            "Train loss: 2.9926939010620117 at epoch 0\n",
            "Train loss: 2.5706429481506348 at epoch 0\n",
            "Train loss: 1.5810896158218384 at epoch 0\n",
            "Train loss: 3.5059821605682373 at epoch 0\n",
            "Train loss: 1.8912605047225952 at epoch 0\n",
            "Train loss: 2.267005681991577 at epoch 0\n",
            "Train loss: 1.6324900388717651 at epoch 0\n",
            "Train loss: 3.669614315032959 at epoch 0\n",
            "Train loss: 2.2695999145507812 at epoch 0\n",
            "Train loss: 2.059739351272583 at epoch 0\n",
            "Train loss: 3.4787795543670654 at epoch 0\n",
            "Train loss: 2.069254159927368 at epoch 0\n",
            "Train loss: 2.494793653488159 at epoch 0\n",
            "Train loss: 2.119034767150879 at epoch 0\n",
            "Train loss: 2.398996591567993 at epoch 0\n",
            "Train loss: 2.31014347076416 at epoch 0\n",
            "Train loss: 1.8952285051345825 at epoch 0\n",
            "Train loss: 2.4991023540496826 at epoch 0\n",
            "Train loss: 2.4413256645202637 at epoch 0\n",
            "Train loss: 1.9940725564956665 at epoch 0\n",
            "Train loss: 2.700214385986328 at epoch 0\n",
            "Train loss: 2.291942596435547 at epoch 0\n",
            "Train loss: 1.8940829038619995 at epoch 0\n",
            "Train loss: 1.6779727935791016 at epoch 0\n",
            "Train loss: 2.1805734634399414 at epoch 0\n",
            "Train loss: 2.4524247646331787 at epoch 0\n",
            "Train loss: 2.0556135177612305 at epoch 0\n",
            "Train loss: 3.275270462036133 at epoch 0\n",
            "Train loss: 2.481541395187378 at epoch 0\n",
            "Train loss: 0.7877147793769836 at epoch 0\n",
            "Train loss: 2.418837308883667 at epoch 0\n",
            "Train loss: 3.7001802921295166 at epoch 0\n",
            "Train loss: 1.740578532218933 at epoch 0\n",
            "Train loss: 2.3010590076446533 at epoch 0\n",
            "Train loss: 2.634000062942505 at epoch 0\n",
            "Train loss: 1.667155146598816 at epoch 0\n",
            "Train loss: 2.3618671894073486 at epoch 0\n",
            "Train loss: 1.5000425577163696 at epoch 0\n",
            "Train loss: 2.255950689315796 at epoch 0\n",
            "Train loss: 2.33727765083313 at epoch 0\n",
            "Train loss: 2.66457200050354 at epoch 0\n",
            "Train loss: 2.4075188636779785 at epoch 0\n",
            "Train loss: 1.1636571884155273 at epoch 0\n",
            "Train loss: 2.8581836223602295 at epoch 0\n",
            "Train loss: 2.3046860694885254 at epoch 0\n",
            "Train loss: 3.0032296180725098 at epoch 0\n",
            "Train loss: 2.2912919521331787 at epoch 0\n",
            "Train loss: 3.509547472000122 at epoch 0\n",
            "Train loss: 2.1285629272460938 at epoch 0\n",
            "Train loss: 2.886838912963867 at epoch 0\n",
            "Train loss: 1.3977744579315186 at epoch 0\n",
            "Train loss: 2.2036070823669434 at epoch 0\n",
            "Train loss: 1.865248203277588 at epoch 0\n",
            "Train loss: 2.0521934032440186 at epoch 0\n",
            "Train loss: 2.5749399662017822 at epoch 0\n",
            "Train loss: 3.132139205932617 at epoch 0\n",
            "Train loss: 1.6078542470932007 at epoch 0\n",
            "Train loss: 2.032557964324951 at epoch 0\n",
            "Train loss: 1.8564214706420898 at epoch 0\n",
            "Train loss: 1.6884760856628418 at epoch 0\n",
            "Train loss: 1.2499324083328247 at epoch 0\n",
            "Train loss: 3.172396421432495 at epoch 0\n",
            "Train loss: 1.7396678924560547 at epoch 0\n",
            "Train loss: 2.89523983001709 at epoch 0\n",
            "Train loss: 2.6371943950653076 at epoch 0\n",
            "Train loss: 4.073699474334717 at epoch 0\n",
            "Train loss: 2.0821897983551025 at epoch 0\n",
            "Train loss: 3.482597827911377 at epoch 0\n",
            "Train loss: 2.1659553050994873 at epoch 0\n",
            "Train loss: 2.3842883110046387 at epoch 0\n",
            "Train loss: 2.7624106407165527 at epoch 0\n",
            "Train loss: 2.958817958831787 at epoch 0\n",
            "Train loss: 1.6569539308547974 at epoch 0\n",
            "Train loss: 3.0743768215179443 at epoch 0\n",
            "Train loss: 2.0072104930877686 at epoch 0\n",
            "Train loss: 1.865007758140564 at epoch 0\n",
            "Train loss: 1.6967726945877075 at epoch 0\n",
            "Train loss: 2.3969037532806396 at epoch 0\n",
            "Train loss: 1.994521141052246 at epoch 0\n",
            "Train loss: 2.2121055126190186 at epoch 0\n",
            "Train loss: 1.7193456888198853 at epoch 0\n",
            "Train loss: 1.3394912481307983 at epoch 0\n",
            "Train loss: 2.707681179046631 at epoch 0\n",
            "Train loss: 1.3771520853042603 at epoch 0\n",
            "Train loss: 2.1699962615966797 at epoch 0\n",
            "Train loss: 1.5754103660583496 at epoch 0\n",
            "Train loss: 1.7899837493896484 at epoch 0\n",
            "Train loss: 1.877955675125122 at epoch 0\n",
            "Train loss: 1.5631858110427856 at epoch 0\n",
            "Train loss: 2.2928521633148193 at epoch 0\n",
            "Train loss: 1.9174290895462036 at epoch 0\n",
            "Train loss: 2.51846981048584 at epoch 0\n",
            "Train loss: 3.9320199489593506 at epoch 0\n",
            "Train loss: 1.719244360923767 at epoch 0\n",
            "Train loss: 4.018701553344727 at epoch 0\n",
            "Train loss: 2.0182368755340576 at epoch 0\n",
            "Train loss: 1.8638945817947388 at epoch 0\n",
            "Train loss: 1.418152928352356 at epoch 0\n",
            "Train loss: 2.261538505554199 at epoch 0\n",
            "Train loss: 1.9348838329315186 at epoch 0\n",
            "Train loss: 1.8767225742340088 at epoch 0\n",
            "Train loss: 2.4006643295288086 at epoch 0\n",
            "Train loss: 2.9080772399902344 at epoch 0\n",
            "Train loss: 2.7944400310516357 at epoch 0\n",
            "Train loss: 2.1496429443359375 at epoch 0\n",
            "Train loss: 2.3833374977111816 at epoch 0\n",
            "Train loss: 2.939220666885376 at epoch 0\n",
            "Train loss: 2.090073347091675 at epoch 0\n",
            "Train loss: 3.4585678577423096 at epoch 0\n",
            "Train loss: 2.374088764190674 at epoch 0\n",
            "Train loss: 2.663262367248535 at epoch 0\n",
            "Train loss: 1.02486252784729 at epoch 0\n",
            "Train loss: 1.4335323572158813 at epoch 0\n",
            "Train loss: 2.617380142211914 at epoch 0\n",
            "Train loss: 1.8257263898849487 at epoch 0\n",
            "Train loss: 3.117901563644409 at epoch 0\n",
            "Train loss: 1.5286320447921753 at epoch 0\n",
            "Train loss: 1.9384878873825073 at epoch 0\n",
            "Train loss: 2.049471855163574 at epoch 0\n",
            "Train loss: 2.8472108840942383 at epoch 0\n",
            "Train loss: 1.6239173412322998 at epoch 0\n",
            "Train loss: 2.428152561187744 at epoch 0\n",
            "Train loss: 1.3876702785491943 at epoch 0\n",
            "Train loss: 2.585909366607666 at epoch 0\n",
            "Train loss: 2.1292381286621094 at epoch 0\n",
            "Train loss: 2.5674631595611572 at epoch 0\n",
            "Train loss: 2.0184426307678223 at epoch 0\n",
            "Train loss: 3.4199349880218506 at epoch 0\n",
            "Train loss: 2.3273534774780273 at epoch 0\n",
            "Train loss: 1.9565593004226685 at epoch 0\n",
            "Train loss: 2.9854495525360107 at epoch 0\n",
            "Train loss: 3.84061336517334 at epoch 0\n",
            "Train loss: 3.287651777267456 at epoch 0\n",
            "Train loss: 1.287135362625122 at epoch 0\n",
            "Train loss: 1.682921051979065 at epoch 0\n",
            "Train loss: 2.6455652713775635 at epoch 0\n",
            "Train loss: 2.288926839828491 at epoch 0\n",
            "Train loss: 3.801490306854248 at epoch 0\n",
            "Train loss: 2.695544719696045 at epoch 0\n",
            "Train loss: 1.6895586252212524 at epoch 0\n",
            "Train loss: 1.8575812578201294 at epoch 0\n",
            "Train loss: 2.5816919803619385 at epoch 0\n",
            "Train loss: 1.8498139381408691 at epoch 0\n",
            "Train loss: 2.0978925228118896 at epoch 0\n",
            "Train loss: 1.9650532007217407 at epoch 0\n",
            "Train loss: 2.3405911922454834 at epoch 0\n",
            "Train loss: 1.2135592699050903 at epoch 0\n",
            "Train loss: 2.7749264240264893 at epoch 0\n",
            "Train loss: 2.686849355697632 at epoch 0\n",
            "Train loss: 2.5962073802948 at epoch 0\n",
            "Train loss: 2.067138671875 at epoch 0\n",
            "Train loss: 2.394193649291992 at epoch 0\n",
            "Train loss: 2.4350779056549072 at epoch 0\n",
            "Train loss: 2.1675214767456055 at epoch 0\n",
            "Train loss: 2.8029770851135254 at epoch 0\n",
            "Train loss: 1.7964797019958496 at epoch 0\n",
            "Train loss: 2.171945571899414 at epoch 0\n",
            "Train loss: 2.032111644744873 at epoch 0\n",
            "Train loss: 2.4310638904571533 at epoch 0\n",
            "Train loss: 1.4729499816894531 at epoch 0\n",
            "Train loss: 2.924611806869507 at epoch 0\n",
            "Train loss: 2.5477683544158936 at epoch 0\n",
            "Train loss: 2.499011516571045 at epoch 0\n",
            "Train loss: 2.6762115955352783 at epoch 0\n",
            "Train loss: 1.4080630540847778 at epoch 0\n",
            "Train loss: 1.752937912940979 at epoch 0\n",
            "Train loss: 1.9903091192245483 at epoch 0\n",
            "Train loss: 2.3895716667175293 at epoch 0\n",
            "Train loss: 2.6801047325134277 at epoch 0\n",
            "Train loss: 2.5463621616363525 at epoch 0\n",
            "Train loss: 1.4723666906356812 at epoch 0\n",
            "Train loss: 1.1485462188720703 at epoch 0\n",
            "Train loss: 2.565988063812256 at epoch 0\n",
            "Train loss: 1.3694912195205688 at epoch 0\n",
            "Train loss: 2.100815534591675 at epoch 0\n",
            "Train loss: 1.9101967811584473 at epoch 0\n",
            "Train loss: 3.006925106048584 at epoch 0\n",
            "Train loss: 1.6776009798049927 at epoch 0\n",
            "Train loss: 2.449500322341919 at epoch 0\n",
            "Train loss: 2.8648698329925537 at epoch 0\n",
            "Train loss: 1.85292649269104 at epoch 0\n",
            "Train loss: 3.0170984268188477 at epoch 0\n",
            "Train loss: 2.07952618598938 at epoch 0\n",
            "Train loss: 1.6912543773651123 at epoch 0\n",
            "Train loss: 2.066694736480713 at epoch 0\n",
            "Train loss: 1.3951401710510254 at epoch 0\n",
            "Train loss: 1.4856935739517212 at epoch 0\n",
            "Train loss: 2.132178544998169 at epoch 0\n",
            "Train loss: 1.2521520853042603 at epoch 0\n",
            "Train loss: 3.1733407974243164 at epoch 0\n",
            "Train loss: 1.2111278772354126 at epoch 0\n",
            "Train loss: 2.0894272327423096 at epoch 0\n",
            "Train loss: 3.618255376815796 at epoch 0\n",
            "Train loss: 2.491567611694336 at epoch 0\n",
            "Train loss: 2.3817172050476074 at epoch 0\n",
            "Train loss: 1.5486407279968262 at epoch 0\n",
            "Train loss: 2.7979557514190674 at epoch 0\n",
            "Train loss: 1.5363364219665527 at epoch 0\n",
            "Train loss: 2.3312296867370605 at epoch 0\n",
            "Train loss: 1.7425799369812012 at epoch 0\n",
            "Train loss: 1.5452988147735596 at epoch 0\n",
            "Train loss: 2.054550886154175 at epoch 0\n",
            "Train loss: 2.6082711219787598 at epoch 0\n",
            "Train loss: 3.338644504547119 at epoch 0\n",
            "Train loss: 1.5171589851379395 at epoch 0\n",
            "Train loss: 2.2732646465301514 at epoch 0\n",
            "Train loss: 3.0546610355377197 at epoch 0\n",
            "Train loss: 1.9107787609100342 at epoch 0\n",
            "Train loss: 1.669832468032837 at epoch 0\n",
            "Train loss: 2.3536574840545654 at epoch 0\n",
            "Train loss: 2.7177653312683105 at epoch 0\n",
            "Train loss: 2.3956592082977295 at epoch 0\n",
            "Train loss: 2.79793643951416 at epoch 0\n",
            "Train loss: 2.8088841438293457 at epoch 0\n",
            "Train loss: 2.672999620437622 at epoch 0\n",
            "Train loss: 2.493278741836548 at epoch 0\n",
            "Train loss: 2.0638856887817383 at epoch 0\n",
            "Train loss: 1.9164923429489136 at epoch 0\n",
            "Train loss: 1.4991098642349243 at epoch 0\n",
            "Train loss: 2.386904716491699 at epoch 0\n",
            "Train loss: 1.7808483839035034 at epoch 0\n",
            "Train loss: 2.653841972351074 at epoch 0\n",
            "Train loss: 2.103565216064453 at epoch 0\n",
            "Train loss: 3.1497433185577393 at epoch 0\n",
            "Train loss: 1.9390233755111694 at epoch 0\n",
            "Train loss: 3.11625337600708 at epoch 0\n",
            "Train loss: 3.0201220512390137 at epoch 0\n",
            "Train loss: 1.9266401529312134 at epoch 0\n",
            "Train loss: 1.5939288139343262 at epoch 0\n",
            "Train loss: 1.776235580444336 at epoch 0\n",
            "Train loss: 1.8894351720809937 at epoch 0\n",
            "Train loss: 1.9890960454940796 at epoch 0\n",
            "Train loss: 2.444612741470337 at epoch 0\n",
            "Train loss: 2.327484369277954 at epoch 0\n",
            "Train loss: 2.3362057209014893 at epoch 0\n",
            "Train loss: 2.022789478302002 at epoch 0\n",
            "Train loss: 1.7353116273880005 at epoch 0\n",
            "Train loss: 1.7147963047027588 at epoch 0\n",
            "Train loss: 2.209397792816162 at epoch 0\n",
            "Train loss: 1.2722901105880737 at epoch 0\n",
            "Train loss: 1.8293226957321167 at epoch 0\n",
            "Train loss: 1.8108354806900024 at epoch 0\n",
            "Train loss: 1.550266146659851 at epoch 0\n",
            "Train loss: 2.2375082969665527 at epoch 0\n",
            "Train loss: 2.5323169231414795 at epoch 0\n",
            "Train loss: 1.4728015661239624 at epoch 0\n",
            "Train loss: 3.7965283393859863 at epoch 0\n",
            "Train loss: 1.9558420181274414 at epoch 0\n",
            "Train loss: 2.6553986072540283 at epoch 0\n",
            "Train loss: 3.019318103790283 at epoch 0\n",
            "Train loss: 3.196608304977417 at epoch 0\n",
            "Train loss: 1.087908387184143 at epoch 0\n",
            "Train loss: 1.8253623247146606 at epoch 0\n",
            "Train loss: 1.8616734743118286 at epoch 0\n",
            "Train loss: 2.828704595565796 at epoch 0\n",
            "Train loss: 2.268002510070801 at epoch 0\n",
            "Train loss: 3.5016727447509766 at epoch 0\n",
            "Train loss: 2.0004210472106934 at epoch 0\n",
            "Train loss: 1.8277301788330078 at epoch 0\n",
            "Train loss: 1.7278426885604858 at epoch 0\n",
            "Train loss: 2.6394317150115967 at epoch 0\n",
            "Train loss: 3.032473087310791 at epoch 0\n",
            "Train loss: 1.837245225906372 at epoch 0\n",
            "Train loss: 2.0573360919952393 at epoch 0\n",
            "Train loss: 2.200383186340332 at epoch 0\n",
            "Train loss: 1.9278149604797363 at epoch 0\n",
            "Train loss: 2.347388982772827 at epoch 0\n",
            "Train loss: 2.022991895675659 at epoch 0\n",
            "Train loss: 3.0241429805755615 at epoch 0\n",
            "Train loss: 2.369023561477661 at epoch 0\n",
            "Train loss: 2.640942096710205 at epoch 0\n",
            "Train loss: 3.416229009628296 at epoch 0\n",
            "Train loss: 1.8418889045715332 at epoch 0\n",
            "Train loss: 2.6386332511901855 at epoch 0\n",
            "Train loss: 2.4041762351989746 at epoch 0\n",
            "Train loss: 2.8618147373199463 at epoch 0\n",
            "Train loss: 2.1300110816955566 at epoch 0\n",
            "Train loss: 2.3244547843933105 at epoch 0\n",
            "Train loss: 1.3025175333023071 at epoch 0\n",
            "Train loss: 2.28267765045166 at epoch 0\n",
            "Train loss: 1.7116351127624512 at epoch 0\n",
            "Train loss: 1.589550256729126 at epoch 0\n",
            "Train loss: 1.8034340143203735 at epoch 0\n",
            "Train loss: 2.672990560531616 at epoch 0\n",
            "Train loss: 3.0951898097991943 at epoch 0\n",
            "Train loss: 2.3166799545288086 at epoch 0\n",
            "Train loss: 2.6326675415039062 at epoch 0\n",
            "Train loss: 1.8182897567749023 at epoch 0\n",
            "Train loss: 2.351870536804199 at epoch 0\n",
            "Train loss: 2.1696157455444336 at epoch 0\n",
            "Train loss: 1.7447432279586792 at epoch 0\n",
            "Train loss: 2.715729236602783 at epoch 0\n",
            "Train loss: 2.079073905944824 at epoch 0\n",
            "Train loss: 2.5907955169677734 at epoch 0\n",
            "Train loss: 2.858285665512085 at epoch 0\n",
            "Train loss: 1.7165188789367676 at epoch 0\n",
            "Train loss: 1.3978588581085205 at epoch 0\n",
            "Train loss: 1.2643369436264038 at epoch 0\n",
            "Train loss: 1.5857845544815063 at epoch 0\n",
            "Train loss: 2.1414575576782227 at epoch 0\n",
            "Train loss: 1.8388973474502563 at epoch 0\n",
            "Train loss: 2.7931673526763916 at epoch 0\n",
            "Train loss: 1.428999662399292 at epoch 0\n",
            "Train loss: 1.0595873594284058 at epoch 0\n",
            "Train loss: 1.3085062503814697 at epoch 0\n",
            "Train loss: 1.9714035987854004 at epoch 0\n",
            "Train loss: 1.750276803970337 at epoch 0\n",
            "Train loss: 2.354994535446167 at epoch 0\n",
            "Train loss: 2.059903621673584 at epoch 0\n",
            "Train loss: 1.7674622535705566 at epoch 0\n",
            "Train loss: 2.112792730331421 at epoch 0\n",
            "Train loss: 1.4442715644836426 at epoch 0\n",
            "Train loss: 1.8673949241638184 at epoch 0\n",
            "Train loss: 3.155806541442871 at epoch 0\n",
            "Train loss: 2.367246150970459 at epoch 0\n",
            "Train loss: 1.5849634408950806 at epoch 0\n",
            "Train loss: 1.0544105768203735 at epoch 0\n",
            "Train loss: 1.882283091545105 at epoch 0\n",
            "Train loss: 1.6559582948684692 at epoch 0\n",
            "Train loss: 2.023458957672119 at epoch 0\n",
            "Train loss: 1.8245134353637695 at epoch 0\n",
            "Train loss: 1.8798247575759888 at epoch 0\n",
            "Train loss: 1.5866799354553223 at epoch 0\n",
            "Train loss: 4.439819812774658 at epoch 0\n",
            "Train loss: 1.6567227840423584 at epoch 0\n",
            "Train loss: 2.083702802658081 at epoch 0\n",
            "Train loss: 1.7895418405532837 at epoch 0\n",
            "Train loss: 2.2117087841033936 at epoch 0\n",
            "Train loss: 2.2309587001800537 at epoch 0\n",
            "Train loss: 1.7778044939041138 at epoch 0\n",
            "Train loss: 2.1313769817352295 at epoch 0\n",
            "Train loss: 1.355772614479065 at epoch 0\n",
            "Train loss: 1.800020456314087 at epoch 0\n",
            "Train loss: 1.8358728885650635 at epoch 0\n",
            "Train loss: 1.6220629215240479 at epoch 0\n",
            "Train loss: 1.4446957111358643 at epoch 0\n",
            "Train loss: 2.1875791549682617 at epoch 0\n",
            "Train loss: 3.203615665435791 at epoch 0\n",
            "Train loss: 2.5678458213806152 at epoch 0\n",
            "Train loss: 2.0702176094055176 at epoch 0\n",
            "Train loss: 1.4176969528198242 at epoch 0\n",
            "Train loss: 1.2782241106033325 at epoch 0\n",
            "Train loss: 2.3847999572753906 at epoch 0\n",
            "Train loss: 2.726560354232788 at epoch 0\n",
            "Train loss: 1.7794264554977417 at epoch 0\n",
            "Train loss: 1.8223133087158203 at epoch 0\n",
            "Train loss: 2.445560932159424 at epoch 0\n",
            "Train loss: 2.3206911087036133 at epoch 0\n",
            "Train loss: 2.3065781593322754 at epoch 0\n",
            "Train loss: 1.384211540222168 at epoch 0\n",
            "Train loss: 1.6153011322021484 at epoch 0\n",
            "Train loss: 2.1707093715667725 at epoch 0\n",
            "Train loss: 2.4902608394622803 at epoch 0\n",
            "Train loss: 2.580641746520996 at epoch 0\n",
            "Train loss: 2.047020673751831 at epoch 0\n",
            "Train loss: 2.1837291717529297 at epoch 0\n",
            "Train loss: 1.9752943515777588 at epoch 0\n",
            "Train loss: 2.0234053134918213 at epoch 0\n",
            "Train loss: 2.042776107788086 at epoch 0\n",
            "Train loss: 2.41896653175354 at epoch 0\n",
            "Train loss: 3.3999111652374268 at epoch 0\n",
            "Train loss: 2.2252912521362305 at epoch 0\n",
            "Train loss: 2.213409662246704 at epoch 0\n",
            "Train loss: 1.4798640012741089 at epoch 0\n",
            "Train loss: 2.0555293560028076 at epoch 0\n",
            "Train loss: 2.336036443710327 at epoch 0\n",
            "Train loss: 2.109924077987671 at epoch 0\n",
            "Train loss: 1.7128936052322388 at epoch 0\n",
            "Train loss: 1.8097493648529053 at epoch 0\n",
            "Train loss: 1.9601038694381714 at epoch 0\n",
            "Train loss: 2.3564059734344482 at epoch 0\n",
            "Train loss: 1.3527274131774902 at epoch 0\n",
            "Train loss: 2.271639585494995 at epoch 0\n",
            "Train loss: 2.3782155513763428 at epoch 0\n",
            "Train loss: 2.627520799636841 at epoch 0\n",
            "Train loss: 2.964489698410034 at epoch 0\n",
            "Train loss: 1.8825048208236694 at epoch 0\n",
            "Train loss: 1.704770803451538 at epoch 0\n",
            "Train loss: 2.882993459701538 at epoch 0\n",
            "Train loss: 2.439180612564087 at epoch 0\n",
            "Train loss: 1.6193634271621704 at epoch 0\n",
            "Train loss: 1.5095908641815186 at epoch 0\n",
            "Train loss: 1.5836771726608276 at epoch 0\n",
            "Train loss: 2.9508354663848877 at epoch 0\n",
            "Train loss: 2.2409496307373047 at epoch 0\n",
            "Train loss: 2.9205076694488525 at epoch 0\n",
            "Train loss: 1.8888095617294312 at epoch 0\n",
            "Train loss: 1.7977237701416016 at epoch 0\n",
            "Train loss: 2.245790958404541 at epoch 0\n",
            "Train loss: 2.853659152984619 at epoch 0\n",
            "Train loss: 1.340553879737854 at epoch 0\n",
            "Train loss: 2.7594387531280518 at epoch 0\n",
            "Train loss: 3.243541955947876 at epoch 0\n",
            "Train loss: 2.319322347640991 at epoch 0\n",
            "Train loss: 2.4694817066192627 at epoch 0\n",
            "Train loss: 2.7382256984710693 at epoch 0\n",
            "Train loss: 2.3082287311553955 at epoch 0\n",
            "Train loss: 3.600830078125 at epoch 0\n",
            "Train loss: 1.9511606693267822 at epoch 0\n",
            "Train loss: 1.7999836206436157 at epoch 0\n",
            "Train loss: 3.557812452316284 at epoch 0\n",
            "Train loss: 2.369658946990967 at epoch 0\n",
            "Train loss: 1.7105095386505127 at epoch 0\n",
            "Train loss: 2.97460675239563 at epoch 0\n",
            "Train loss: 1.4882900714874268 at epoch 0\n",
            "Train loss: 2.9922471046447754 at epoch 0\n",
            "Train loss: 1.9714583158493042 at epoch 0\n",
            "Train loss: 2.727869987487793 at epoch 0\n",
            "Train loss: 1.840779185295105 at epoch 0\n",
            "Train loss: 1.932416558265686 at epoch 0\n",
            "Train loss: 1.1623053550720215 at epoch 0\n",
            "Train loss: 2.359449625015259 at epoch 0\n",
            "Train loss: 1.9593631029129028 at epoch 0\n",
            "Train loss: 2.9675681591033936 at epoch 0\n",
            "Train loss: 2.07108473777771 at epoch 0\n",
            "Train loss: 1.6526315212249756 at epoch 0\n",
            "Train loss: 1.987202763557434 at epoch 0\n",
            "Train loss: 1.8000630140304565 at epoch 0\n",
            "Train loss: 2.5915002822875977 at epoch 0\n",
            "Train loss: 1.6158407926559448 at epoch 0\n",
            "Train loss: 1.5349910259246826 at epoch 0\n",
            "Train loss: 1.9933409690856934 at epoch 0\n",
            "Train loss: 1.4012815952301025 at epoch 0\n",
            "Train loss: 1.1826598644256592 at epoch 0\n",
            "Train loss: 2.3009142875671387 at epoch 0\n",
            "Train loss: 2.030243396759033 at epoch 0\n",
            "Train loss: 1.81575608253479 at epoch 0\n",
            "Train loss: 1.9261399507522583 at epoch 0\n",
            "Train loss: 1.6893056631088257 at epoch 0\n",
            "Train loss: 1.9510760307312012 at epoch 0\n",
            "Train loss: 2.9334027767181396 at epoch 0\n",
            "Train loss: 2.7997825145721436 at epoch 0\n",
            "Train loss: 3.112462043762207 at epoch 0\n",
            "Train loss: 2.1057584285736084 at epoch 0\n",
            "Train loss: 1.0707247257232666 at epoch 0\n",
            "Train loss: 2.607330560684204 at epoch 0\n",
            "Train loss: 2.4045207500457764 at epoch 0\n",
            "Train loss: 1.868117094039917 at epoch 0\n",
            "Train loss: 2.64514422416687 at epoch 0\n",
            "Train loss: 3.4729197025299072 at epoch 0\n",
            "Train loss: 2.3294014930725098 at epoch 0\n",
            "Train loss: 0.8953689932823181 at epoch 0\n",
            "Train loss: 1.7922275066375732 at epoch 0\n",
            "Train loss: 1.5482192039489746 at epoch 0\n",
            "Train loss: 2.190063238143921 at epoch 0\n",
            "Train loss: 1.7737956047058105 at epoch 0\n",
            "Train loss: 3.019409418106079 at epoch 0\n",
            "Train loss: 1.5486286878585815 at epoch 0\n",
            "Train loss: 2.499814748764038 at epoch 0\n",
            "Train loss: 2.094434976577759 at epoch 0\n",
            "Train loss: 1.8930333852767944 at epoch 0\n",
            "Train loss: 4.172913551330566 at epoch 0\n",
            "Train loss: 1.9048136472702026 at epoch 0\n",
            "Train loss: 2.6462154388427734 at epoch 0\n",
            "Train loss: 3.534477472305298 at epoch 0\n",
            "Train loss: 3.096940040588379 at epoch 0\n",
            "Train loss: 2.1425724029541016 at epoch 0\n",
            "Train loss: 1.188586711883545 at epoch 0\n",
            "Train loss: 2.5844972133636475 at epoch 0\n",
            "Train loss: 2.3720459938049316 at epoch 0\n",
            "Train loss: 1.1361652612686157 at epoch 0\n",
            "Train loss: 2.2823750972747803 at epoch 0\n",
            "Train loss: 1.4999898672103882 at epoch 0\n",
            "Train loss: 1.812329649925232 at epoch 0\n",
            "Train loss: 1.404695987701416 at epoch 0\n",
            "Train loss: 1.4806311130523682 at epoch 0\n",
            "Train loss: 2.198855400085449 at epoch 0\n",
            "Train loss: 1.9237624406814575 at epoch 0\n",
            "Train loss: 1.8728808164596558 at epoch 0\n",
            "Train loss: 2.610844850540161 at epoch 0\n",
            "Train loss: 1.5576077699661255 at epoch 0\n",
            "Train loss: 1.5328428745269775 at epoch 0\n",
            "Train loss: 2.9269297122955322 at epoch 0\n",
            "Train loss: 2.382094144821167 at epoch 0\n",
            "Train loss: 2.316756248474121 at epoch 0\n",
            "Train loss: 2.2121005058288574 at epoch 0\n",
            "Train loss: 2.8436198234558105 at epoch 0\n",
            "Train loss: 1.7528690099716187 at epoch 0\n",
            "Train loss: 1.2974828481674194 at epoch 0\n",
            "Train loss: 2.7622063159942627 at epoch 0\n",
            "Train loss: 1.8412142992019653 at epoch 0\n",
            "Train loss: 2.2315516471862793 at epoch 0\n",
            "Train loss: 1.8796803951263428 at epoch 0\n",
            "Train loss: 2.094381809234619 at epoch 0\n",
            "Train loss: 2.9966511726379395 at epoch 0\n",
            "Train loss: 2.1507203578948975 at epoch 0\n",
            "Train loss: 3.19154691696167 at epoch 0\n",
            "Train loss: 3.2142133712768555 at epoch 0\n",
            "Train loss: 2.2157108783721924 at epoch 0\n",
            "Train loss: 1.3502695560455322 at epoch 0\n",
            "Train loss: 1.9121029376983643 at epoch 0\n",
            "Train loss: 1.6942473649978638 at epoch 0\n",
            "Train loss: 2.0361716747283936 at epoch 0\n",
            "Train loss: 3.1499807834625244 at epoch 0\n",
            "Train loss: 1.8447781801223755 at epoch 0\n",
            "Train loss: 2.607508420944214 at epoch 0\n",
            "Train loss: 2.6851558685302734 at epoch 0\n",
            "Train loss: 1.9522404670715332 at epoch 0\n",
            "Train loss: 2.8973426818847656 at epoch 0\n",
            "Train loss: 2.0113508701324463 at epoch 0\n",
            "Train loss: 2.13765287399292 at epoch 0\n",
            "Train loss: 1.7740535736083984 at epoch 0\n",
            "Train loss: 1.9541281461715698 at epoch 0\n",
            "Train loss: 2.1500580310821533 at epoch 0\n",
            "Train loss: 1.5565546751022339 at epoch 0\n",
            "Train loss: 1.2307013273239136 at epoch 0\n",
            "Train loss: 3.547102451324463 at epoch 0\n",
            "Train loss: 2.31680965423584 at epoch 0\n",
            "Train loss: 2.740859270095825 at epoch 0\n",
            "Train loss: 2.905428647994995 at epoch 0\n",
            "Train loss: 1.6629457473754883 at epoch 0\n",
            "Train loss: 1.627935767173767 at epoch 0\n",
            "Train loss: 1.9274314641952515 at epoch 0\n",
            "Train loss: 2.3036279678344727 at epoch 0\n",
            "Train loss: 2.133441209793091 at epoch 0\n",
            "Train loss: 2.359469413757324 at epoch 0\n",
            "Train loss: 1.894438624382019 at epoch 0\n",
            "Train loss: 2.2965404987335205 at epoch 0\n",
            "Train loss: 2.6914234161376953 at epoch 0\n",
            "Train loss: 3.3563127517700195 at epoch 0\n",
            "Train loss: 3.012054681777954 at epoch 0\n",
            "Train loss: 2.2234315872192383 at epoch 0\n",
            "Train loss: 2.0832715034484863 at epoch 0\n",
            "Train loss: 1.429561734199524 at epoch 0\n",
            "Train loss: 1.139497995376587 at epoch 0\n",
            "Train loss: 1.311182975769043 at epoch 0\n",
            "Train loss: 1.2713325023651123 at epoch 0\n",
            "Train loss: 1.9412155151367188 at epoch 0\n",
            "Train loss: 1.471640944480896 at epoch 0\n",
            "Train loss: 1.886942982673645 at epoch 0\n",
            "Train loss: 1.535883903503418 at epoch 0\n",
            "Train loss: 2.473980188369751 at epoch 0\n",
            "Train loss: 2.330683946609497 at epoch 0\n",
            "Train loss: 1.2649991512298584 at epoch 0\n",
            "Train loss: 2.324721336364746 at epoch 0\n",
            "Train loss: 2.331160545349121 at epoch 0\n",
            "Train loss: 2.0350146293640137 at epoch 0\n",
            "Train loss: 3.1476573944091797 at epoch 0\n",
            "Train loss: 2.090864658355713 at epoch 0\n",
            "Train loss: 2.4897615909576416 at epoch 0\n",
            "Train loss: 2.6391263008117676 at epoch 0\n",
            "Train loss: 2.176520824432373 at epoch 0\n",
            "Train loss: 2.243870496749878 at epoch 0\n",
            "Train loss: 2.9661550521850586 at epoch 0\n",
            "Train loss: 3.5839664936065674 at epoch 0\n",
            "Train loss: 3.145559310913086 at epoch 0\n",
            "Train loss: 1.73198664188385 at epoch 0\n",
            "Train loss: 1.8676917552947998 at epoch 0\n",
            "Train loss: 1.85692298412323 at epoch 0\n",
            "Train loss: 1.7652041912078857 at epoch 0\n",
            "Train loss: 1.8982419967651367 at epoch 0\n",
            "Train loss: 0.9370297193527222 at epoch 0\n",
            "Train loss: 2.0003316402435303 at epoch 0\n",
            "Train loss: 2.985100507736206 at epoch 0\n",
            "Train loss: 2.0114920139312744 at epoch 0\n",
            "Train loss: 3.258216619491577 at epoch 0\n",
            "Train loss: 1.2957775592803955 at epoch 0\n",
            "Train loss: 1.8575950860977173 at epoch 0\n",
            "Train loss: 2.2623448371887207 at epoch 0\n",
            "Train loss: 1.6176074743270874 at epoch 0\n",
            "Train loss: 1.814372181892395 at epoch 0\n",
            "Train loss: 0.7919495105743408 at epoch 0\n",
            "Train loss: 1.4795068502426147 at epoch 0\n",
            "Train loss: 1.8906466960906982 at epoch 0\n",
            "Train loss: 2.5992822647094727 at epoch 0\n",
            "Train loss: 2.3709564208984375 at epoch 0\n",
            "Train loss: 3.03230619430542 at epoch 0\n",
            "Train loss: 2.5290005207061768 at epoch 0\n",
            "Train loss: 2.682197332382202 at epoch 0\n",
            "Train loss: 1.356400728225708 at epoch 0\n",
            "Train loss: 1.8601446151733398 at epoch 0\n",
            "Train loss: 1.3138383626937866 at epoch 0\n",
            "Train loss: 2.0019142627716064 at epoch 0\n",
            "Train loss: 1.1943038702011108 at epoch 0\n",
            "Train loss: 1.9731600284576416 at epoch 0\n",
            "Train loss: 2.955500364303589 at epoch 0\n",
            "Train loss: 2.422830104827881 at epoch 0\n",
            "Train loss: 2.239091157913208 at epoch 0\n",
            "Train loss: 2.005326271057129 at epoch 0\n",
            "Train loss: 2.108745574951172 at epoch 0\n",
            "Train loss: 2.069129467010498 at epoch 0\n",
            "Train loss: 2.039522409439087 at epoch 0\n",
            "Train loss: 2.2585833072662354 at epoch 0\n",
            "Train loss: 1.6678946018218994 at epoch 0\n",
            "Train loss: 3.8460536003112793 at epoch 0\n",
            "Train loss: 1.3606537580490112 at epoch 0\n",
            "Train loss: 2.003051519393921 at epoch 0\n",
            "Train loss: 2.3378777503967285 at epoch 0\n",
            "Train loss: 1.8580646514892578 at epoch 0\n",
            "Train loss: 2.0486083030700684 at epoch 0\n",
            "Train loss: 2.701831340789795 at epoch 0\n",
            "Train loss: 2.2710049152374268 at epoch 0\n",
            "Train loss: 1.289311170578003 at epoch 0\n",
            "Train loss: 2.372196912765503 at epoch 0\n",
            "Train loss: 2.3577826023101807 at epoch 0\n",
            "Train loss: 3.6249451637268066 at epoch 0\n",
            "Train loss: 2.7995519638061523 at epoch 0\n",
            "Train loss: 1.8633651733398438 at epoch 0\n",
            "Train loss: 2.0121867656707764 at epoch 0\n",
            "Train loss: 2.923896074295044 at epoch 0\n",
            "Train loss: 3.600451946258545 at epoch 0\n",
            "Train loss: 1.9801816940307617 at epoch 0\n",
            "Train loss: 1.9347295761108398 at epoch 0\n",
            "Train loss: 2.597560167312622 at epoch 0\n",
            "Train loss: 2.5173871517181396 at epoch 0\n",
            "Train loss: 1.6227455139160156 at epoch 0\n",
            "Train loss: 2.5514562129974365 at epoch 0\n",
            "Train loss: 3.204559087753296 at epoch 0\n",
            "Train loss: 2.081941843032837 at epoch 0\n",
            "Train loss: 1.1657794713974 at epoch 0\n",
            "Train loss: 2.208918809890747 at epoch 0\n",
            "Train loss: 1.8830053806304932 at epoch 0\n",
            "Train loss: 1.662713646888733 at epoch 0\n",
            "Train loss: 2.8457727432250977 at epoch 0\n",
            "Train loss: 1.9567492008209229 at epoch 0\n",
            "Train loss: 2.446687698364258 at epoch 0\n",
            "Train loss: 1.0899497270584106 at epoch 0\n",
            "Train loss: 1.7338582277297974 at epoch 0\n",
            "Train loss: 2.6850876808166504 at epoch 0\n",
            "Train loss: 1.7318236827850342 at epoch 0\n",
            "Train loss: 1.2192190885543823 at epoch 0\n",
            "Train loss: 1.766157627105713 at epoch 0\n",
            "Train loss: 3.0573596954345703 at epoch 0\n",
            "Train loss: 2.3355562686920166 at epoch 0\n",
            "Train loss: 1.7551628351211548 at epoch 0\n",
            "Train loss: 4.065770149230957 at epoch 0\n",
            "Train loss: 0.9875701069831848 at epoch 0\n",
            "Train loss: 2.519117593765259 at epoch 0\n",
            "Train loss: 1.897918701171875 at epoch 0\n",
            "Train loss: 1.5649558305740356 at epoch 0\n",
            "Train loss: 1.5904648303985596 at epoch 0\n",
            "Train loss: 1.617263913154602 at epoch 0\n",
            "Train loss: 2.5084919929504395 at epoch 0\n",
            "Train loss: 1.3680827617645264 at epoch 0\n",
            "Train loss: 1.5187222957611084 at epoch 0\n",
            "Train loss: 2.5198569297790527 at epoch 0\n",
            "Train loss: 1.6330130100250244 at epoch 0\n",
            "Train loss: 1.5588414669036865 at epoch 0\n",
            "Train loss: 2.6437630653381348 at epoch 0\n",
            "Train loss: 1.6354789733886719 at epoch 0\n",
            "Train loss: 2.6540842056274414 at epoch 0\n",
            "Train loss: 1.861640453338623 at epoch 0\n",
            "Train loss: 2.6171631813049316 at epoch 0\n",
            "Train loss: 2.1564574241638184 at epoch 0\n",
            "Train loss: 1.879629135131836 at epoch 0\n",
            "Train loss: 2.0685172080993652 at epoch 0\n",
            "Train loss: 1.8956551551818848 at epoch 0\n",
            "Train loss: 1.9164584875106812 at epoch 0\n",
            "Train loss: 2.563664674758911 at epoch 0\n",
            "Train loss: 2.3624889850616455 at epoch 0\n",
            "Train loss: 2.095827102661133 at epoch 0\n",
            "Train loss: 2.721991539001465 at epoch 0\n",
            "Train loss: 2.6489100456237793 at epoch 0\n",
            "Train loss: 2.7692925930023193 at epoch 0\n",
            "Train loss: 2.3082079887390137 at epoch 0\n",
            "Train loss: 2.3711020946502686 at epoch 0\n",
            "Train loss: 1.3323999643325806 at epoch 0\n",
            "Train loss: 3.6685938835144043 at epoch 0\n",
            "Train loss: 2.0971992015838623 at epoch 0\n",
            "Train loss: 2.961460590362549 at epoch 0\n",
            "Train loss: 1.9046168327331543 at epoch 0\n",
            "Train loss: 1.9641669988632202 at epoch 0\n",
            "Train loss: 2.1673965454101562 at epoch 0\n",
            "Train loss: 1.9180103540420532 at epoch 0\n",
            "Train loss: 1.4068939685821533 at epoch 0\n",
            "Train loss: 1.7747777700424194 at epoch 0\n",
            "Train loss: 2.7542786598205566 at epoch 0\n",
            "Train loss: 2.234232187271118 at epoch 0\n",
            "Train loss: 1.6697133779525757 at epoch 0\n",
            "Train loss: 3.6450843811035156 at epoch 0\n",
            "Train loss: 2.5298619270324707 at epoch 0\n",
            "Train loss: 2.0636398792266846 at epoch 0\n",
            "Train loss: 2.4515256881713867 at epoch 0\n",
            "Train loss: 3.026296377182007 at epoch 0\n",
            "Train loss: 2.2463297843933105 at epoch 0\n",
            "Train loss: 2.0682945251464844 at epoch 0\n",
            "Train loss: 1.8995100259780884 at epoch 0\n",
            "Train loss: 2.567432403564453 at epoch 0\n",
            "Train loss: 2.7910544872283936 at epoch 0\n",
            "Train loss: 2.3720204830169678 at epoch 0\n",
            "Train loss: 1.9779715538024902 at epoch 0\n",
            "Train loss: 2.668149948120117 at epoch 0\n",
            "Train loss: 2.45477294921875 at epoch 0\n",
            "Train loss: 1.6270910501480103 at epoch 0\n",
            "Train loss: 1.8882768154144287 at epoch 0\n",
            "Train loss: 2.8173985481262207 at epoch 0\n",
            "Train loss: 1.2649723291397095 at epoch 0\n",
            "Train loss: 3.178715705871582 at epoch 0\n",
            "Train loss: 1.8713406324386597 at epoch 0\n",
            "Train loss: 2.9520370960235596 at epoch 0\n",
            "Train loss: 1.6352636814117432 at epoch 0\n",
            "Train loss: 2.1912949085235596 at epoch 0\n",
            "Train loss: 1.8756153583526611 at epoch 0\n",
            "Train loss: 1.4721680879592896 at epoch 0\n",
            "Train loss: 3.69315767288208 at epoch 0\n",
            "Train loss: 2.2030320167541504 at epoch 0\n",
            "Train loss: 1.4560177326202393 at epoch 0\n",
            "Train loss: 1.45951247215271 at epoch 0\n",
            "Train loss: 3.1932806968688965 at epoch 0\n",
            "Train loss: 2.397040367126465 at epoch 0\n",
            "Train loss: 1.8992496728897095 at epoch 0\n",
            "Train loss: 1.2247222661972046 at epoch 0\n",
            "Train loss: 2.396517515182495 at epoch 0\n",
            "Train loss: 1.2577581405639648 at epoch 0\n",
            "Train loss: 1.5181535482406616 at epoch 0\n",
            "Train loss: 2.2730612754821777 at epoch 0\n",
            "Train loss: 3.039553165435791 at epoch 0\n",
            "Train loss: 2.061728000640869 at epoch 0\n",
            "Train loss: 2.3218607902526855 at epoch 0\n",
            "Train loss: 1.954001784324646 at epoch 0\n",
            "Train loss: 2.2564151287078857 at epoch 0\n",
            "Train loss: 2.3306939601898193 at epoch 0\n",
            "Train loss: 2.1409988403320312 at epoch 0\n",
            "Train loss: 1.9531214237213135 at epoch 0\n",
            "Train loss: 1.8084584474563599 at epoch 0\n",
            "Train loss: 2.690748453140259 at epoch 0\n",
            "Train loss: 2.3758747577667236 at epoch 0\n",
            "Train loss: 2.3693509101867676 at epoch 0\n",
            "Train loss: 2.912318229675293 at epoch 0\n",
            "Train loss: 2.7809486389160156 at epoch 0\n",
            "Train loss: 2.171380043029785 at epoch 0\n",
            "Train loss: 1.3009326457977295 at epoch 0\n",
            "Train loss: 1.4610809087753296 at epoch 0\n",
            "Train loss: 2.4305989742279053 at epoch 0\n",
            "Train loss: 2.693325996398926 at epoch 0\n",
            "Train loss: 1.9658156633377075 at epoch 0\n",
            "Train loss: 2.8483786582946777 at epoch 0\n",
            "Train loss: 2.7058446407318115 at epoch 0\n",
            "Train loss: 1.90837562084198 at epoch 0\n",
            "Train loss: 1.6991775035858154 at epoch 0\n",
            "Train loss: 1.86958646774292 at epoch 0\n",
            "Train loss: 2.1501550674438477 at epoch 0\n",
            "Train loss: 1.455613136291504 at epoch 0\n",
            "Train loss: 1.6055018901824951 at epoch 0\n",
            "Train loss: 1.920918583869934 at epoch 0\n",
            "Train loss: 2.810044050216675 at epoch 0\n",
            "Train loss: 1.6786112785339355 at epoch 0\n",
            "Train loss: 3.1326234340667725 at epoch 0\n",
            "Train loss: 1.8641830682754517 at epoch 0\n",
            "Train loss: 1.902753233909607 at epoch 0\n",
            "Train loss: 2.1448707580566406 at epoch 0\n",
            "Train loss: 2.1901988983154297 at epoch 0\n",
            "Train loss: 1.738888144493103 at epoch 0\n",
            "Train loss: 2.333894968032837 at epoch 0\n",
            "Train loss: 2.0921781063079834 at epoch 0\n",
            "Train loss: 1.6285511255264282 at epoch 0\n",
            "Train loss: 1.2634071111679077 at epoch 0\n",
            "Train loss: 1.004250407218933 at epoch 0\n",
            "Train loss: 1.3428921699523926 at epoch 0\n",
            "Train loss: 2.826017141342163 at epoch 0\n",
            "Train loss: 1.9283783435821533 at epoch 0\n",
            "Train loss: 3.5143916606903076 at epoch 0\n",
            "Train loss: 2.669861316680908 at epoch 0\n",
            "Train loss: 2.2354445457458496 at epoch 0\n",
            "Train loss: 1.3914728164672852 at epoch 0\n",
            "Train loss: 2.5403525829315186 at epoch 0\n",
            "Train loss: 1.133621335029602 at epoch 0\n",
            "Train loss: 2.3004629611968994 at epoch 0\n",
            "Train loss: 3.9448695182800293 at epoch 0\n",
            "Train loss: 1.6119579076766968 at epoch 0\n",
            "Train loss: 1.904299020767212 at epoch 0\n",
            "Train loss: 3.3227732181549072 at epoch 0\n",
            "Train loss: 1.9577304124832153 at epoch 0\n",
            "Train loss: 1.971436858177185 at epoch 0\n",
            "Train loss: 1.9610413312911987 at epoch 0\n",
            "Train loss: 2.088283061981201 at epoch 0\n",
            "Train loss: 2.5709028244018555 at epoch 0\n",
            "Train loss: 2.676064968109131 at epoch 0\n",
            "Train loss: 1.5219342708587646 at epoch 0\n",
            "Train loss: 1.80908203125 at epoch 0\n",
            "Train loss: 2.705660581588745 at epoch 0\n",
            "Train loss: 1.492030382156372 at epoch 0\n",
            "Train loss: 2.0135860443115234 at epoch 0\n",
            "Train loss: 2.3048198223114014 at epoch 0\n",
            "Train loss: 2.312948226928711 at epoch 0\n",
            "Train loss: 1.8804341554641724 at epoch 0\n",
            "Train loss: 2.2191002368927 at epoch 0\n",
            "Train loss: 1.9823421239852905 at epoch 0\n",
            "Train loss: 2.5289394855499268 at epoch 0\n",
            "Train loss: 2.8358240127563477 at epoch 0\n",
            "Train loss: 3.2422468662261963 at epoch 0\n",
            "Train loss: 1.5389519929885864 at epoch 0\n",
            "Train loss: 1.7894140481948853 at epoch 0\n",
            "Train loss: 1.494736671447754 at epoch 0\n",
            "Train loss: 3.3901991844177246 at epoch 0\n",
            "Train loss: 1.8969963788986206 at epoch 0\n",
            "Train loss: 2.2555220127105713 at epoch 0\n",
            "Train loss: 2.4178788661956787 at epoch 0\n",
            "Train loss: 2.739934206008911 at epoch 0\n",
            "Train loss: 1.3722432851791382 at epoch 0\n",
            "Train loss: 1.9029593467712402 at epoch 0\n",
            "Train loss: 1.091149091720581 at epoch 0\n",
            "Train loss: 1.378398060798645 at epoch 0\n",
            "Train loss: 1.7863458395004272 at epoch 0\n",
            "Train loss: 2.642869234085083 at epoch 0\n",
            "Train loss: 2.2434842586517334 at epoch 0\n",
            "Train loss: 2.8992466926574707 at epoch 0\n",
            "Train loss: 1.9992444515228271 at epoch 0\n",
            "Train loss: 2.7921247482299805 at epoch 0\n",
            "Train loss: 2.959843635559082 at epoch 0\n",
            "Train loss: 2.889357089996338 at epoch 0\n",
            "Train loss: 2.1915054321289062 at epoch 0\n",
            "Train loss: 2.451432466506958 at epoch 0\n",
            "Train loss: 2.0864858627319336 at epoch 0\n",
            "Train loss: 1.9947378635406494 at epoch 0\n",
            "Train loss: 2.1396870613098145 at epoch 0\n",
            "Train loss: 1.790208101272583 at epoch 0\n",
            "Train loss: 1.9716246128082275 at epoch 0\n",
            "Train loss: 1.9132705926895142 at epoch 0\n",
            "Train loss: 1.0464576482772827 at epoch 0\n",
            "Train loss: 2.006194829940796 at epoch 0\n",
            "Train loss: 2.838301420211792 at epoch 0\n",
            "Train loss: 2.400559902191162 at epoch 0\n",
            "Train loss: 1.5178630352020264 at epoch 0\n",
            "Train loss: 2.2494394779205322 at epoch 0\n",
            "Train loss: 2.688429117202759 at epoch 0\n",
            "Train loss: 2.9565560817718506 at epoch 0\n",
            "Train loss: 1.6078964471817017 at epoch 0\n",
            "Train loss: 2.0606954097747803 at epoch 0\n",
            "Train loss: 2.5137813091278076 at epoch 0\n",
            "Train loss: 2.1909193992614746 at epoch 0\n",
            "Train loss: 2.7449910640716553 at epoch 0\n",
            "Train loss: 1.5936154127120972 at epoch 0\n",
            "Train loss: 2.8502843379974365 at epoch 0\n",
            "Train loss: 1.624525785446167 at epoch 0\n",
            "Train loss: 2.5128986835479736 at epoch 0\n",
            "Train loss: 1.6789953708648682 at epoch 0\n",
            "Train loss: 2.3648366928100586 at epoch 0\n",
            "Train loss: 2.642324447631836 at epoch 0\n",
            "Train loss: 2.0711829662323 at epoch 0\n",
            "Train loss: 2.5909552574157715 at epoch 0\n",
            "Train loss: 1.9742372035980225 at epoch 0\n",
            "Train loss: 3.014504909515381 at epoch 0\n",
            "Train loss: 1.7350292205810547 at epoch 0\n",
            "Train loss: 1.8828586339950562 at epoch 0\n",
            "Train loss: 1.7535400390625 at epoch 0\n",
            "Train loss: 2.0194251537323 at epoch 0\n",
            "Train loss: 3.7362871170043945 at epoch 0\n",
            "Train loss: 2.5630083084106445 at epoch 0\n",
            "Train loss: 3.152803659439087 at epoch 0\n",
            "Train loss: 1.1647343635559082 at epoch 0\n",
            "Train loss: 1.4139469861984253 at epoch 0\n",
            "Train loss: 3.094893217086792 at epoch 0\n",
            "Train loss: 1.305564522743225 at epoch 0\n",
            "Train loss: 2.1875853538513184 at epoch 0\n",
            "Train loss: 3.152010202407837 at epoch 0\n",
            "Train loss: 2.168705463409424 at epoch 0\n",
            "Train loss: 2.4052040576934814 at epoch 0\n",
            "Train loss: 3.1095802783966064 at epoch 0\n",
            "Train loss: 2.94059681892395 at epoch 0\n",
            "Train loss: 2.4846298694610596 at epoch 0\n",
            "Train loss: 2.1210784912109375 at epoch 0\n",
            "Train loss: 1.401452660560608 at epoch 0\n",
            "Train loss: 1.5738710165023804 at epoch 0\n",
            "Train loss: 1.2595674991607666 at epoch 0\n",
            "Train loss: 2.477525472640991 at epoch 0\n",
            "Train loss: 1.4900383949279785 at epoch 0\n",
            "Train loss: 1.6820158958435059 at epoch 0\n",
            "Train loss: 2.0450754165649414 at epoch 0\n",
            "Train loss: 2.7984890937805176 at epoch 0\n",
            "Train loss: 1.5307656526565552 at epoch 0\n",
            "Train loss: 2.07677960395813 at epoch 0\n",
            "Train loss: 1.6948224306106567 at epoch 0\n",
            "Train loss: 2.2325942516326904 at epoch 0\n",
            "Train loss: 2.2029943466186523 at epoch 0\n",
            "Train loss: 2.381540298461914 at epoch 0\n",
            "Train loss: 2.2651054859161377 at epoch 0\n",
            "Train loss: 2.5796964168548584 at epoch 0\n",
            "Train loss: 3.3670852184295654 at epoch 0\n",
            "Train loss: 1.933444619178772 at epoch 0\n",
            "Train loss: 1.5776602029800415 at epoch 0\n",
            "Train loss: 3.170074224472046 at epoch 0\n",
            "Train loss: 2.662311553955078 at epoch 0\n",
            "Train loss: 2.0544025897979736 at epoch 0\n",
            "Train loss: 1.280541181564331 at epoch 0\n",
            "Train loss: 1.3758715391159058 at epoch 0\n",
            "Train loss: 1.9994871616363525 at epoch 0\n",
            "Train loss: 1.677450180053711 at epoch 0\n",
            "Train loss: 1.539076328277588 at epoch 0\n",
            "Train loss: 2.1706669330596924 at epoch 0\n",
            "Train loss: 2.0801546573638916 at epoch 0\n",
            "Train loss: 1.5273836851119995 at epoch 0\n",
            "Train loss: 1.1261789798736572 at epoch 0\n",
            "Train loss: 1.860219955444336 at epoch 0\n",
            "Train loss: 1.5368307828903198 at epoch 0\n",
            "Train loss: 1.6646195650100708 at epoch 0\n",
            "Train loss: 1.5060827732086182 at epoch 0\n",
            "Train loss: 2.0149829387664795 at epoch 0\n",
            "Train loss: 2.0006096363067627 at epoch 0\n",
            "Train loss: 2.8625006675720215 at epoch 0\n",
            "Train loss: 1.7763370275497437 at epoch 0\n",
            "Train loss: 2.0979933738708496 at epoch 0\n",
            "Train loss: 2.2319746017456055 at epoch 0\n",
            "Train loss: 2.282813549041748 at epoch 0\n",
            "Train loss: 2.8901703357696533 at epoch 0\n",
            "Train loss: 1.9909840822219849 at epoch 0\n",
            "Train loss: 2.47581148147583 at epoch 0\n",
            "Train loss: 1.294006109237671 at epoch 0\n",
            "Train loss: 2.0975403785705566 at epoch 0\n",
            "Train loss: 2.5435292720794678 at epoch 0\n",
            "Train loss: 2.186115264892578 at epoch 0\n",
            "Train loss: 2.889357805252075 at epoch 0\n",
            "Train loss: 3.4574787616729736 at epoch 0\n",
            "Train loss: 1.8277744054794312 at epoch 0\n",
            "Train loss: 3.5974981784820557 at epoch 0\n",
            "Train loss: 1.7767316102981567 at epoch 0\n",
            "Train loss: 1.8126463890075684 at epoch 0\n",
            "Train loss: 2.9113516807556152 at epoch 0\n",
            "Train loss: 1.4593881368637085 at epoch 0\n",
            "Train loss: 2.0457026958465576 at epoch 0\n",
            "Train loss: 1.6974587440490723 at epoch 0\n",
            "Train loss: 1.670867681503296 at epoch 0\n",
            "Train loss: 2.998934745788574 at epoch 0\n",
            "Train loss: 2.368722438812256 at epoch 0\n",
            "Train loss: 1.8659106492996216 at epoch 0\n",
            "Train loss: 1.4243433475494385 at epoch 0\n",
            "Train loss: 3.162360429763794 at epoch 0\n",
            "Train loss: 1.3514528274536133 at epoch 0\n",
            "Train loss: 1.6515660285949707 at epoch 0\n",
            "Train loss: 1.9154828786849976 at epoch 0\n",
            "Train loss: 1.157112717628479 at epoch 0\n",
            "Train loss: 2.2205452919006348 at epoch 0\n",
            "Train loss: 2.1152701377868652 at epoch 0\n",
            "Train loss: 2.672037363052368 at epoch 0\n",
            "Train loss: 1.3620848655700684 at epoch 0\n",
            "Train loss: 2.6411712169647217 at epoch 0\n",
            "Train loss: 1.4234107732772827 at epoch 0\n",
            "Train loss: 2.739950180053711 at epoch 0\n",
            "Train loss: 1.165490746498108 at epoch 0\n",
            "Train loss: 2.2257955074310303 at epoch 0\n",
            "Train loss: 2.357516050338745 at epoch 0\n",
            "Train loss: 2.0953102111816406 at epoch 0\n",
            "Train loss: 2.119436025619507 at epoch 0\n",
            "Train loss: 2.8441216945648193 at epoch 0\n",
            "Train loss: 2.2608165740966797 at epoch 0\n",
            "Train loss: 3.3992698192596436 at epoch 0\n",
            "Train loss: 1.41752028465271 at epoch 0\n",
            "Train loss: 1.609784483909607 at epoch 0\n",
            "Train loss: 2.6195623874664307 at epoch 0\n",
            "Train loss: 3.5482399463653564 at epoch 0\n",
            "Train loss: 1.7378965616226196 at epoch 0\n",
            "Train loss: 2.206714153289795 at epoch 0\n",
            "Train loss: 1.8014895915985107 at epoch 0\n",
            "Train loss: 1.859724521636963 at epoch 0\n",
            "Train loss: 2.4546093940734863 at epoch 0\n",
            "Train loss: 2.0774967670440674 at epoch 0\n",
            "Train loss: 3.805302858352661 at epoch 0\n",
            "Train loss: 1.5891656875610352 at epoch 0\n",
            "Train loss: 2.2695302963256836 at epoch 0\n",
            "Train loss: 2.421466112136841 at epoch 0\n",
            "Train loss: 3.4328551292419434 at epoch 0\n",
            "Train loss: 2.4337844848632812 at epoch 0\n",
            "Train loss: 1.6644381284713745 at epoch 0\n",
            "Train loss: 1.7874071598052979 at epoch 0\n",
            "Train loss: 1.0194718837738037 at epoch 0\n",
            "Train loss: 1.893551230430603 at epoch 0\n",
            "Train loss: 2.165025234222412 at epoch 0\n",
            "Train loss: 2.376675605773926 at epoch 0\n",
            "Train loss: 1.447938323020935 at epoch 0\n",
            "Train loss: 2.8447530269622803 at epoch 0\n",
            "Train loss: 1.6457808017730713 at epoch 0\n",
            "Train loss: 1.922875165939331 at epoch 0\n",
            "Train loss: 1.6058332920074463 at epoch 0\n",
            "Train loss: 1.8287209272384644 at epoch 0\n",
            "Train loss: 2.095736503601074 at epoch 0\n",
            "Train loss: 1.631339430809021 at epoch 0\n",
            "Train loss: 2.5173768997192383 at epoch 0\n",
            "Train loss: 2.247896909713745 at epoch 0\n",
            "Train loss: 2.8831944465637207 at epoch 0\n",
            "Train loss: 3.0001518726348877 at epoch 0\n",
            "Train loss: 1.9942529201507568 at epoch 0\n",
            "Train loss: 1.6712778806686401 at epoch 0\n",
            "Train loss: 2.3269636631011963 at epoch 0\n",
            "Train loss: 2.0619332790374756 at epoch 0\n",
            "Train loss: 3.283668279647827 at epoch 0\n",
            "Train loss: 1.203416109085083 at epoch 0\n",
            "Train loss: 3.7891335487365723 at epoch 0\n",
            "Train loss: 1.8102869987487793 at epoch 0\n",
            "Train loss: 1.8192601203918457 at epoch 0\n",
            "Train loss: 2.261986255645752 at epoch 0\n",
            "Train loss: 2.549250364303589 at epoch 0\n",
            "Train loss: 2.3519935607910156 at epoch 0\n",
            "Train loss: 1.359192967414856 at epoch 0\n",
            "Train loss: 1.8276441097259521 at epoch 0\n",
            "Train loss: 1.6409780979156494 at epoch 0\n",
            "Train loss: 2.877613067626953 at epoch 0\n",
            "Train loss: 1.215863823890686 at epoch 0\n",
            "Train loss: 1.7659238576889038 at epoch 0\n",
            "Train loss: 1.7250747680664062 at epoch 0\n",
            "Train loss: 2.1587462425231934 at epoch 0\n",
            "Train loss: 1.6549642086029053 at epoch 0\n",
            "Train loss: 2.0778493881225586 at epoch 0\n",
            "Train loss: 1.9816995859146118 at epoch 0\n",
            "Train loss: 2.418259382247925 at epoch 0\n",
            "Train loss: 3.595933198928833 at epoch 0\n",
            "Train loss: 2.1630711555480957 at epoch 0\n",
            "Train loss: 3.4727537631988525 at epoch 0\n",
            "Train loss: 1.3747577667236328 at epoch 0\n",
            "Train loss: 2.101884365081787 at epoch 0\n",
            "Train loss: 2.2316157817840576 at epoch 0\n",
            "Train loss: 2.355989933013916 at epoch 0\n",
            "Train loss: 2.190606117248535 at epoch 0\n",
            "Train loss: 3.016547441482544 at epoch 0\n",
            "Train loss: 2.3705241680145264 at epoch 0\n",
            "Train loss: 1.6908233165740967 at epoch 0\n",
            "Train loss: 2.1842925548553467 at epoch 0\n",
            "Train loss: 2.719409942626953 at epoch 0\n",
            "Train loss: 1.5422258377075195 at epoch 0\n",
            "Train loss: 1.7122533321380615 at epoch 0\n",
            "Train loss: 2.091768741607666 at epoch 0\n",
            "Train loss: 1.2673639059066772 at epoch 0\n",
            "Train loss: 2.7779619693756104 at epoch 0\n",
            "Train loss: 1.9713495969772339 at epoch 0\n",
            "Train loss: 1.2047699689865112 at epoch 0\n",
            "Train loss: 2.0457468032836914 at epoch 0\n",
            "Train loss: 3.241546154022217 at epoch 0\n",
            "Train loss: 2.0705461502075195 at epoch 0\n",
            "Train loss: 1.755041480064392 at epoch 0\n",
            "Train loss: 2.2513976097106934 at epoch 0\n",
            "Train loss: 1.6004947423934937 at epoch 0\n",
            "Train loss: 1.6328420639038086 at epoch 0\n",
            "Train loss: 1.8578510284423828 at epoch 0\n",
            "Train loss: 1.1454968452453613 at epoch 0\n",
            "Train loss: 2.6747143268585205 at epoch 0\n",
            "Train loss: 2.4420182704925537 at epoch 0\n",
            "Train loss: 2.275505542755127 at epoch 0\n",
            "Train loss: 1.3777321577072144 at epoch 0\n",
            "Train loss: 2.270669937133789 at epoch 0\n",
            "Train loss: 3.270765781402588 at epoch 0\n",
            "Train loss: 3.314608573913574 at epoch 0\n",
            "Train loss: 2.194634437561035 at epoch 0\n",
            "Train loss: 1.9198343753814697 at epoch 0\n",
            "Train loss: 2.2643911838531494 at epoch 0\n",
            "Train loss: 2.6207666397094727 at epoch 0\n",
            "Train loss: 1.5658290386199951 at epoch 0\n",
            "Train loss: 2.204251766204834 at epoch 0\n",
            "Train loss: 2.3954532146453857 at epoch 0\n",
            "Train loss: 3.5397486686706543 at epoch 0\n",
            "Train loss: 3.041912078857422 at epoch 0\n",
            "Train loss: 2.984677791595459 at epoch 0\n",
            "Train loss: 1.5025510787963867 at epoch 0\n",
            "Train loss: 2.1615915298461914 at epoch 0\n",
            "Train loss: 3.068375587463379 at epoch 0\n",
            "Train loss: 3.210775375366211 at epoch 0\n",
            "Train loss: 2.0424139499664307 at epoch 0\n",
            "Train loss: 2.2389323711395264 at epoch 0\n",
            "Train loss: 1.9904450178146362 at epoch 0\n",
            "Train loss: 2.1700029373168945 at epoch 0\n",
            "Train loss: 1.4333696365356445 at epoch 0\n",
            "Train loss: 2.440396785736084 at epoch 0\n",
            "Train loss: 1.3877712488174438 at epoch 0\n",
            "Train loss: 1.8658367395401 at epoch 0\n",
            "Train loss: 1.6691628694534302 at epoch 0\n",
            "Train loss: 3.1695973873138428 at epoch 0\n",
            "Train loss: 0.9519138932228088 at epoch 0\n",
            "Train loss: 2.247546434402466 at epoch 0\n",
            "Train loss: 2.495842933654785 at epoch 0\n",
            "Train loss: 1.8804994821548462 at epoch 0\n",
            "Train loss: 1.6837385892868042 at epoch 0\n",
            "Train loss: 1.691393256187439 at epoch 0\n",
            "Train loss: 2.898128032684326 at epoch 0\n",
            "Train loss: 4.362444877624512 at epoch 0\n",
            "Train loss: 1.451051115989685 at epoch 0\n",
            "Train loss: 1.8204721212387085 at epoch 0\n",
            "Train loss: 2.2852725982666016 at epoch 0\n",
            "Train loss: 1.6706912517547607 at epoch 0\n",
            "Train loss: 2.5714304447174072 at epoch 0\n",
            "Train loss: 3.11464262008667 at epoch 0\n",
            "Train loss: 1.404557704925537 at epoch 0\n",
            "Train loss: 2.290337324142456 at epoch 0\n",
            "Train loss: 2.413024663925171 at epoch 0\n",
            "Train loss: 2.433105707168579 at epoch 0\n",
            "Train loss: 2.2792961597442627 at epoch 0\n",
            "Train loss: 2.3836731910705566 at epoch 0\n",
            "Train loss: 1.9979064464569092 at epoch 0\n",
            "Train loss: 2.5848259925842285 at epoch 0\n",
            "Train loss: 3.075594902038574 at epoch 0\n",
            "Train loss: 2.605247735977173 at epoch 0\n",
            "Train loss: 2.4749035835266113 at epoch 0\n",
            "Train loss: 2.6265177726745605 at epoch 0\n",
            "Train loss: 2.377763032913208 at epoch 0\n",
            "Train loss: 2.2771542072296143 at epoch 0\n",
            "Train loss: 2.5161337852478027 at epoch 0\n",
            "Train loss: 2.310232400894165 at epoch 0\n",
            "Train loss: 1.856475830078125 at epoch 0\n",
            "Train loss: 2.577819585800171 at epoch 0\n",
            "Train loss: 2.6993813514709473 at epoch 0\n",
            "Train loss: 1.5878629684448242 at epoch 0\n",
            "Train loss: 2.5186612606048584 at epoch 0\n",
            "Train loss: 2.548851490020752 at epoch 0\n",
            "Train loss: 2.095266580581665 at epoch 0\n",
            "Train loss: 1.6515682935714722 at epoch 0\n",
            "Train loss: 2.307713747024536 at epoch 0\n",
            "Train loss: 1.7918692827224731 at epoch 0\n",
            "Train loss: 3.954390525817871 at epoch 0\n",
            "Train loss: 1.5909768342971802 at epoch 0\n",
            "Train loss: 1.1694778203964233 at epoch 0\n",
            "Train loss: 2.6733012199401855 at epoch 0\n",
            "Train loss: 1.5683292150497437 at epoch 0\n",
            "Train loss: 2.630620002746582 at epoch 0\n",
            "Train loss: 2.817650079727173 at epoch 0\n",
            "Train loss: 1.8071529865264893 at epoch 0\n",
            "Train loss: 1.9467710256576538 at epoch 0\n",
            "Train loss: 1.886717438697815 at epoch 0\n",
            "Train loss: 1.923777461051941 at epoch 0\n",
            "Train loss: 1.9028774499893188 at epoch 0\n",
            "Train loss: 2.6361021995544434 at epoch 0\n",
            "Train loss: 2.3448128700256348 at epoch 0\n",
            "Train loss: 1.8897968530654907 at epoch 0\n",
            "Train loss: 1.2113593816757202 at epoch 0\n",
            "Train loss: 1.8819955587387085 at epoch 0\n",
            "Train loss: 2.1001076698303223 at epoch 0\n",
            "Train loss: 2.279409646987915 at epoch 0\n",
            "Train loss: 2.326098680496216 at epoch 0\n",
            "Train loss: 2.7707161903381348 at epoch 0\n",
            "Train loss: 2.2895543575286865 at epoch 0\n",
            "Train loss: 1.8557989597320557 at epoch 0\n",
            "Train loss: 2.2546401023864746 at epoch 0\n",
            "Train loss: 2.075901746749878 at epoch 0\n",
            "Train loss: 1.5610512495040894 at epoch 0\n",
            "Train loss: 2.3033454418182373 at epoch 0\n",
            "Train loss: 2.644331455230713 at epoch 0\n",
            "Train loss: 1.532852292060852 at epoch 0\n",
            "Train loss: 1.7095929384231567 at epoch 0\n",
            "Train loss: 2.432802677154541 at epoch 0\n",
            "Train loss: 1.8648790121078491 at epoch 0\n",
            "Train loss: 2.2300984859466553 at epoch 0\n",
            "Train loss: 1.914829134941101 at epoch 0\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(Config.TRAIN_EPOCHS):\n",
        "  train_model(epoch, train_dataset.tokenizer, model, device, train_loader, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Im1S_6x4_Osr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948bea30-ece1-4a51-f9d9-be5c62f3d005"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(Config.VAL_EPOCHS):\n",
        "  predictions, summary = val_model(epoch, val_dataset.tokenizer, model, device, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dtry16bpAMhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27233ae-23e6-4d9c-84c4-898b1cdf79b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual Summary\n",
            "A 31-year-old man has been arrested for masturbating mid-air and inappropriately touching a woman passenger on board a Bengaluru-Mumbai flight. The woman co-passenger woke up from her sleep to find the man masturbating and raised an alarm. When the airline crew reached the seat, the man denied the woman's allegation, however, he was fixing the zip of his trousers.\n",
            "Predicted Summary\n",
            "The man was arrested on Tuesday morning for masturbating and inappropriately touching a woman passenger on a flight. The man, Sabeen Hamza, started taking advantage of the situation and moved his hand on her. He was taken away after he woken up to the horror of the middle-aged man masturbating while looking at her.\n",
            "\n",
            "\n",
            "\n",
            "Actual Summary\n",
            "Actress Shraddha Kapoor, while speaking about reports of her dating Farhan Akhtar, has said that fiction can go to incredible heights. She said, \"I choose to ignore them and just focus on my work,\" and added that she's friends with Farhan. Earlier, reports of Shraddha moving in with Farhan had surfaced online.\n",
            "Predicted Summary\n",
            "Shraddha Kapoor and Farhan Akhtar's rumoured relationship continues to be the hottest topic of discussion for gossipmongers. \"The level of fiction can go to incredible heights. I choose to ignore them and just focus on my work,\" Shraddha said. She added, \"The link-up rumours have not affected me at all, but this time it did as it involved my family.\"\n",
            "\n",
            "\n",
            "\n",
            "Actual Summary\n",
            "The Supreme Court has said it will examine whether IIT Kanpur can withhold the result of a student expelled in 2016 for sexually harassing a female student. The man had filed a plea for his result to be declared, saying he wasn't given a copy of the complaint. He also said he wasn't allowed to defend himself before the expulsion.\n",
            "Predicted Summary\n",
            "A bench of justices has said it will examine whether an IIT can withhold the results of a final-year student, who was terminated after being held guilty in a sexual harassment case. The student claimed that the results of the final semester should be given to the student as the delay is jeopardising his career. He also tried to support his defence by introducing a large number of documents and a list of students who would appear as witnesses in the inquiry.\n",
            "\n",
            "\n",
            "\n",
            "Actual Summary\n",
            "The police on Saturday arrested three persons from a gang of five alleged criminals in Greater Noida, after a shootout in which one of them was injured and two managed to flee. The police had acted on a tip-off and discovered later that the gang from Bulandshahr, was involved in a robbery in Noida's Kasna this month.\n",
            "Predicted Summary\n",
            "Police on Saturday arrested three people after a shoot-out with a gang of five alleged criminals in Greater Noida. The accused, who were on a bike, pushed Bhati's bag which had cash in it and fled. The police recovered?4.20 lakh, two countrymade pistols, four live cartridges, one knife and two bikes from the accused.\n",
            "\n",
            "\n",
            "\n",
            "Actual Summary\n",
            "After the counting of votes began for all the 403 seats in Uttar Pradesh, the Bharatiya Janata Party crossed the halfway mark with a lead in 271 seats. The incumbent Samajwadi Party and its alliance with Congress is leading only in 77 seats across the state whereas the Bahujan Samaj Party was leading in 28 seats.\n",
            "Predicted Summary\n",
            "\"We stand resolute & committed to our belief in an India united in strength & purposeOur fight continues and will not end till we win the hearts and minds of peopleCongratulations to @Capt_amarinder Singh & congratulated him on the win in Punjab. Also wished him a happy birthday and prayed for his long and healthy life.\"\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  print('Actual Summary')\n",
        "  print(f'{summary[i]}')\n",
        "  print('Predicted Summary')\n",
        "  print(f'{predictions[i]}')\n",
        "  print('\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "c6O95Hhg_27R"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join(os.getcwd(), 't5model.pth')\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5273c6e912174685bd478ae95a4cd647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_627d0100f5034ad2a9899cd6fd6e534e",
              "IPY_MODEL_fa72dcb77df74acfba650f1383261e6b",
              "IPY_MODEL_b6c04d150a69466e9fb35674cc6f8a8a"
            ],
            "layout": "IPY_MODEL_b9fe96f43d874459a54183919589509c"
          }
        },
        "627d0100f5034ad2a9899cd6fd6e534e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c2548d3c5414f919488fbb494da5005",
            "placeholder": "​",
            "style": "IPY_MODEL_0af5fadefe3b40d8a0d2c1ad46296d5e",
            "value": ""
          }
        },
        "fa72dcb77df74acfba650f1383261e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76def81e75da4d6482bf5bd2c9b14f46",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1611415a1fc43ffa15ab733e4baadaa",
            "value": 0
          }
        },
        "b6c04d150a69466e9fb35674cc6f8a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9843882cfb1e47c89129a349b176fb81",
            "placeholder": "​",
            "style": "IPY_MODEL_b2f5aa7c4af44fb39c2147fc929b4d66",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "b9fe96f43d874459a54183919589509c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2548d3c5414f919488fbb494da5005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af5fadefe3b40d8a0d2c1ad46296d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76def81e75da4d6482bf5bd2c9b14f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a1611415a1fc43ffa15ab733e4baadaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9843882cfb1e47c89129a349b176fb81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f5aa7c4af44fb39c2147fc929b4d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad3d067e8e2a477aa09113a6a01ed081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e1a19b3f5f44c15ae8e2a148439585a",
              "IPY_MODEL_15560e5e66034b1f94fb5123e3bfb684",
              "IPY_MODEL_debe180065ab41e384bb6a0c9a253e34"
            ],
            "layout": "IPY_MODEL_a96d91b349674ebea858911f272bc9c5"
          }
        },
        "9e1a19b3f5f44c15ae8e2a148439585a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a893bb481ae44e4bdcda75637192800",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd81a8693ae406688cec0b189598a60",
            "value": "Downloading: 100%"
          }
        },
        "15560e5e66034b1f94fb5123e3bfb684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b2d940855f47bd91fe8e81b49a0fbc",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e227c505776943eeb13b59777e676f52",
            "value": 791656
          }
        },
        "debe180065ab41e384bb6a0c9a253e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a588340a73544738bcaa5d17b198759",
            "placeholder": "​",
            "style": "IPY_MODEL_628f527741094e909ac5a5c53dfac24d",
            "value": " 792k/792k [00:01&lt;00:00, 524kB/s]"
          }
        },
        "a96d91b349674ebea858911f272bc9c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a893bb481ae44e4bdcda75637192800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd81a8693ae406688cec0b189598a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88b2d940855f47bd91fe8e81b49a0fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e227c505776943eeb13b59777e676f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a588340a73544738bcaa5d17b198759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628f527741094e909ac5a5c53dfac24d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9637848b238a45c1a1cdb63a79f18ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba1231681a33461e87edf3666d4d7fc5",
              "IPY_MODEL_04826699bf514c3ab73810e52b866b52",
              "IPY_MODEL_f8b3e624953740759b5f9724b388cbc3"
            ],
            "layout": "IPY_MODEL_f329aad072d2404cbf732e1953485b7a"
          }
        },
        "ba1231681a33461e87edf3666d4d7fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0582e8d103ce430aaae6231fc9095f43",
            "placeholder": "​",
            "style": "IPY_MODEL_851bc9a82d424c498c56d5f6d83d4d8d",
            "value": "Downloading: 100%"
          }
        },
        "04826699bf514c3ab73810e52b866b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c527eaeca5714da395a5a9633fa096fc",
            "max": 1199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1df3cf28559f45f28ecd0566e17d4dba",
            "value": 1199
          }
        },
        "f8b3e624953740759b5f9724b388cbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4e8df09d0e5457489d404c4d28d9f9e",
            "placeholder": "​",
            "style": "IPY_MODEL_a069e50e54eb488894718fbf757f8dbc",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 31.7kB/s]"
          }
        },
        "f329aad072d2404cbf732e1953485b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0582e8d103ce430aaae6231fc9095f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851bc9a82d424c498c56d5f6d83d4d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c527eaeca5714da395a5a9633fa096fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df3cf28559f45f28ecd0566e17d4dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4e8df09d0e5457489d404c4d28d9f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a069e50e54eb488894718fbf757f8dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d69fb25d3222405da276d4428342f24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82aa212ead654d3fa535d55a1da1e7e1",
              "IPY_MODEL_36fb1ecbea9849769a8a8b53a0c9c2b7",
              "IPY_MODEL_349d91e5385e4edc842f8ebdf41b5ce0"
            ],
            "layout": "IPY_MODEL_6901f05fda3d4b8da51610cc05afd96b"
          }
        },
        "82aa212ead654d3fa535d55a1da1e7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f676d1c2f4b4de8acf36d0420a9272b",
            "placeholder": "​",
            "style": "IPY_MODEL_1ae84d3d149f4cc38113c4138acb20bb",
            "value": "Downloading: 100%"
          }
        },
        "36fb1ecbea9849769a8a8b53a0c9c2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e456154efc584a89bb2e16e09fd37e93",
            "max": 1197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22bb946dfec24863a2368b02bbd0efb5",
            "value": 1197
          }
        },
        "349d91e5385e4edc842f8ebdf41b5ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d88f0a8540455ca6f3f324809c2c5a",
            "placeholder": "​",
            "style": "IPY_MODEL_efba70ee9b7445e899526167d6a0f181",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 34.6kB/s]"
          }
        },
        "6901f05fda3d4b8da51610cc05afd96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f676d1c2f4b4de8acf36d0420a9272b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae84d3d149f4cc38113c4138acb20bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e456154efc584a89bb2e16e09fd37e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22bb946dfec24863a2368b02bbd0efb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51d88f0a8540455ca6f3f324809c2c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efba70ee9b7445e899526167d6a0f181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "172e3848b22a4d0b932e91d48167f022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d295708685f45cfa59abbeddfd9605f",
              "IPY_MODEL_56cec9bdf9a546f19f43143b82a60361",
              "IPY_MODEL_6a77c83804a441059c59aa42f45ec415"
            ],
            "layout": "IPY_MODEL_96c4c2e41e3a4231861ab1794fea2a34"
          }
        },
        "9d295708685f45cfa59abbeddfd9605f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8fb326afdf4bef853e70e2576d7aee",
            "placeholder": "​",
            "style": "IPY_MODEL_08b4c8ad052a4744a86c0bd4636e44a0",
            "value": "Downloading: 100%"
          }
        },
        "56cec9bdf9a546f19f43143b82a60361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e75876423db342b598853f40e5306589",
            "max": 242065649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd15b7a9b8a94177ba7e90cc5861533d",
            "value": 242065649
          }
        },
        "6a77c83804a441059c59aa42f45ec415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312b31c648be4880832670bd2940da0f",
            "placeholder": "​",
            "style": "IPY_MODEL_26fa51bd6d35490f971aaf7d5be7199d",
            "value": " 242M/242M [00:04&lt;00:00, 61.2MB/s]"
          }
        },
        "96c4c2e41e3a4231861ab1794fea2a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8fb326afdf4bef853e70e2576d7aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b4c8ad052a4744a86c0bd4636e44a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e75876423db342b598853f40e5306589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd15b7a9b8a94177ba7e90cc5861533d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "312b31c648be4880832670bd2940da0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26fa51bd6d35490f971aaf7d5be7199d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}